<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>11zHexo</title>
  
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://www.sun11.me/"/>
  <updated>2016-02-07T12:15:46.722Z</updated>
  <id>http://www.sun11.me/</id>
  
  <author>
    <name>Starsky Wong</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Rosmin与Rossum</title>
    <link href="http://www.sun11.me/blog/2013/rosmin-and-rossum/"/>
    <id>http://www.sun11.me/blog/2013/rosmin-and-rossum/</id>
    <published>2013-08-10T11:45:02.000Z</published>
    <updated>2016-02-07T12:15:46.722Z</updated>
    
    <content type="html">&lt;p&gt;Rossum demo:&lt;/p&gt;
&lt;div class=&quot;video-container&quot;&gt;&lt;br&gt;&lt;iframe height=&quot;270&quot; width=&quot;480&quot; src=&quot;http://player.youku.com/embed/XNTY0MTUwMTMy?x&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/div&gt;

&lt;p&gt;Rosmin demo:&lt;/p&gt;
&lt;div class=&quot;video-container&quot;&gt;&lt;br&gt;&lt;iframe height=&quot;270&quot; width=&quot;480&quot; src=&quot;http://player.youku.com/embed/XNDg2OTMzNDEy&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/div&gt;

&lt;h3 id=&quot;Rosmin&quot;&gt;&lt;a href=&quot;#Rosmin&quot; class=&quot;headerlink&quot; title=&quot;Rosmin&quot;&gt;&lt;/a&gt;Rosmin&lt;/h3&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://code.google.com/p/wtfrobot-rosmin/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://code.google.com/p/wtfrobot-rosmin/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;相关文章：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/8029640/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rosmin–OpenCV Color Blob Tracker on Android&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/8034640/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Android下PocketSphinx的离线语音识别&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173609/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rosmin–OpenCV Color Blob Tracker on Android&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173619/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rosmin–两台Android手机的Socket双向通信&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173631/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rosmin–在Android上绘制小车行进路线图并标记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173643/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rosmin–折腾USB Host Shield的日子&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rosmin机器人是我们去年（2012年）制作的一个使用Arduino驱动的小型移动机器人，连接上Android手机，可以完成手机控制的基本运动，追踪乒乓球，以QR码为人工路标移动到指定区域，搜寻目标，视频监控等等。&lt;/p&gt;
&lt;p&gt;硬件结构：&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/54389a22c578eb6789380abdc70ea156.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;软件结构：&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/fa93e566fdba33847d86c97c66e9f6fa.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;图像处理&lt;/p&gt;
&lt;p&gt;利用Android版OpenCV的ColorBlobTrack，控制舵机追踪乒乓球一类有明显颜色特征的物体。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;语音识别&lt;/p&gt;
&lt;p&gt;利用CMU Sphinx语音库实现的小范围离线语音识别，识别速度、准确度都还不错，而且是离线的，不需要连接网络。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Google ADK Mega2560&lt;/p&gt;
&lt;p&gt;使用Google ADK Mega2560 通过USB线与Android手机相连，让小车由小车上搭载的手机运行的服务端程序控制，另外另一台Android设备通过WiFi连接到小车上的手机作为客户端可对小车远程控制。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;陀螺仪&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;用陀螺仪的角加速度信息计算出角度，综合手机发出的控制命令绘制小车运行轨迹。&lt;/p&gt;
&lt;p&gt;实现的功能有：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;基本运动：用Android设备控制小车完成基本运动，可以用控制界面的按钮和语音来操控。如前进，后退，停止，左转，右转，车身左转90度，车身右转90度，舵机云台的转动等。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;追踪乒乓球： 由小车上的Android手机做图像处理获取小球坐标，通过Arduino控制舵机对正小球。根据小球偏离中心位置的距离调整运动速度。详见这篇：&lt;a href=&quot;http://blog.csdn.net/sununs11/article/details/8034294&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rosmin–OpenCV Color Blob Tracker on Android&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/e69e6efc3938f834503de96fbe0068d6.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;以QR码为人工路标的导航： 我们设计了一个以QR码作为人工路标的导航策略，根据超声波传感器检测拐角，利用QR码提供的信息和陀螺仪传感器的信息运动到指定区域。会有一篇水论文，不过现在还没发出来。&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/c6b152e0d811b66b675a416fe8ded013.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;绘制运动轨迹： 我们利用Android上的Google Maps控件做了一个绘制小车运动轨迹的程序，由小车上手机陀螺仪获取角加速度，计算出角度。不知是我们算法不行还是手机加速度计不够精确，用加速度计算出的里程误差太大根本用不了。于是我们就给小车一个恒定的速度，综合控制命令的信息（比如前进后退停止）来绘制轨迹。在客户端可以显示出小车的运行轨迹，还有QR码路标和目标的位置。详见这篇：&lt;a href=&quot;http://blog.csdn.net/f_season/article/details/9171523&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;在Android上绘制小车行进路线图并标记&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/2685dfa7f0443ccf12d4a01a1c3b2568.jpeg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;寻找目标： 不断转动寻找目标，发现目标以后就向目标前进。根据目标区域面积判断是否足够靠近，足够靠近了就认为到达了目标自动停止。关于怎么检测目标和计算目标区域面积仍然在：&lt;a href=&quot;http://blog.csdn.net/sununs11/article/details/8034294&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rosmin–OpenCV Color Blob Tracker on Android&lt;/a&gt;&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/e1bace65dd4c9c1c7e48d3eaaed20aa4.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;视频监控： 用手机的WiFi Camera应用即可，可以通过PC端的Web界面控制。&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/840de7c5837e4b7d544d47284c2d5cbd.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;h3 id=&quot;Rossum&quot;&gt;&lt;a href=&quot;#Rossum&quot; class=&quot;headerlink&quot; title=&quot;Rossum&quot;&gt;&lt;/a&gt;Rossum&lt;/h3&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://code.google.com/p/wtfrobot-rossum/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://code.google.com/p/wtfrobot-rossum/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;相关文章：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173633/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rossum–Android上ROS开发介绍与安装简介&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9881749/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rossum–PID与里程计&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9881771/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rossum–slam&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9881815/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rossum–Android上ROS开发——android_core创建一个android应用&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9881859/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rossum–ROSjava-android控制ROS机器人&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9881889/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rossum–ROSjava的消息发送&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9881965/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rossum–tpofinder 平面纹理物体识别&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rossum是我们以ROS机器人操作系统为核心做的一个自主导航机器人，名字来自于《罗萨姆的万能机器人( Rossum’s Universal Robots)》里的Rossum一词。使用 Kinect 传感器模拟激光测距仪,Arduino 控制器驱动电机控制机器人运动,Atom上网本置于机器人内作为主要的处理设备。&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/5ad0fba96ad2991910975a436aeb4d9d.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;实现的功能：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;基本运动控制： 机器人运动模式为轮式运动,由两个驱动轮驱动机器人运&lt;br&gt;动,一个万向轮辅助,采用 PI 反馈,闭环控制机器人速度,可以精确平滑&lt;br&gt;的控制机器人的运动,同时利用编码器获取的数据,由运动学模型推算机&lt;br&gt;器人的当前坐标系位姿。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;语音控制： 通过 Android 手机发送语音控制机器人运动,可进行离线英文&lt;br&gt;语音识别(和Rosmin相同)，在线中文语音识别(讯飞)。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;跟随运动： 即turtlebot_follower，使机器人与人保持一定距离并正对人体,当人转向或移动时,机器人相应跟随人体转向和移动。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;同时定位与地图构建(SLAM)： 移动机器人在未知环境中依靠传感器获取&lt;br&gt;的信息进行环境建模,同时利用所创建的环境地图估计其本身的位姿。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;自主导航： 在构建出静态地图的基础上,实现机器人从一个位置运动到地&lt;br&gt;图上的另一个指定位置。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;物体识别： 利用tpofinder,实现识别有纹理特征的物体,如书本封面,咖啡盒等，识别后用TTS发声，通过舵机云台对准物体。详见：&lt;a href=&quot;http://blog.csdn.net/sununs11/article/details/9180085&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Rossum–tpofinder 平面纹理物体识别&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;最开始确定方案的时候我们找到了&lt;a href=&quot;http://www.hessmer.org/blog/2011/04/10/2d-slam-with-ros-and-kinect/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Dr. Rainer Hessmer的一篇文章&lt;/a&gt;,它是用Kinect来模拟激光测距仪来做SLAM的，里程计只靠电机上的编码器。他的博客上讲得非常详细，Arduino的介绍，Kinect模拟激光测距仪，惯性导航，SLAM和路径规划的参数这些全都有。当时我们啥都不懂，就把他的博客打印出来一篇一篇地看。&lt;/p&gt;
&lt;p&gt;由于时间很紧，而且在机器人功能还没完全实现前就要写各种文档，我们真正用在这个机器人身上的开发时间很少，甚至可能不如Rosmin，但这个项目却是准备时间最长的，从一开始接触ROS，Android编程，Python，长时间犹豫不决地选购底盘，到后来的调试SLAM耗时有半年，调试SLAM和导航实际时间也就一个多月。&lt;/p&gt;
&lt;p&gt;一开始我还想在ARM上实现它。那个时候ROS的网站上还没有Ubuntu ARM的源，但是刚刚发布ROS Groovy，把构建工具由rosbuild改成了catkin，还给出了详细的编译步骤。于是我就照着步骤编译了一下，&lt;a href=&quot;http://www.sun11.me/blog/ros-on-arm--native-compile-ros-on-rk3066/&quot;&gt;核心包比较顺利地编译成功了&lt;/a&gt;。不过现在即使官方网站有源了，除了核心的库外，其它比较上层的包多数都没有构建成功。用它来做难度太大，而且性能不太好，于是我还是放弃了。图个方便不想遇到驱动问题，而且那时侯我们时间也比较紧了，所以没用mini-itx主板什么的，直接用了10寸的Atom上网本。至于底盘，在ROS的qq群里刚好发现有人出售专门用于ROS的机器人底盘&lt;a href=&quot;http://boomrangrobot.sinaapp.com/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Boomerang&lt;/a&gt;，于是我们就直接买了，包括它整个亚克力板的外壳和两个带编码器的电机、轮子。&lt;/p&gt;
&lt;p&gt;虽然我们找到了这么详细的教程，不过要适配上我们的机器人硬件仍然有很多麻烦。Dr. Rainer Hessmer使用的ros版本是electric，而我们要用fuerte，有一些代码要改，比如参数的双引号什么的。还有一些包被废弃了，改名了，要把launch文件改一下。还有Kinect放置的位置和轮子的距离参数之类的，里程计的调试耗费了最长时间。但是编码器精确度有限，到最后里程计也还是很不准的。在我们视频里可以发现，其实机器人的位置估计是很不准的，万幸的是可以用SLAM算法纠正过来，在SLAM建图的时候注意对准拐角，建出的地图勉强可用，我们还可以用GIMP或者其它图片编辑工具小小滴修正一下，用来导航效果还行。SLAM的参数我们一开始尝试调过，不过后来觉得调整的意义不大，因为Dr. Rainer Hessmer做的已经很好了，我们效果没他的好主要原因应该是里程计。关于PID和里程计：&lt;a href=&quot;http://blog.csdn.net/xiaoqiaoaidianzi/article/details/9179809/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/xiaoqiaoaidianzi/article/details/9179809/&lt;/a&gt;,slam:&lt;a href=&quot;http://blog.csdn.net/xiaoqiaoaidianzi/article/details/9190829/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.csdn.net/xiaoqiaoaidianzi/article/details/9190829/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;地图手工修正前后对比：&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/1aeabdfde10505cca6a2d87994b19dcf.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;最后，其实我开始想实现的远远不止这些，我还想用OpenCV的blob检测来绘制出空中乒乓球的运动轨迹，利用运动轨迹做一些有意思的事情，让机器人具有简单的“认知”，还有三维的rgbd-slam，还有PCL的三维物体识别，还有利用语音识别让机器人完成一些有逻辑的任务，可惜时间远远比我们预料的少，遇到的问题远远比我们预料的多，我们的精力也有限，仍然有一些遗憾吧，现在我们WTFRobot团队的三人都已经加入考研大军了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/0123ae700d696feab9ee6379956a1512.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/a26081e9e8c6b4a7f6a87984574eac06.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;Rossum demo:&lt;/p&gt;
&lt;div class=&quot;video-container&quot;&gt;&lt;br&gt;&lt;iframe  height=270 width=480 src=&quot;http://player.youku.com/embed/XNTY0MTUwMTMy?x&quot; frameborder=0 allowfullscreen&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/div&gt;

&lt;p&gt;Rosmin demo:&lt;/p&gt;
&lt;div class=&quot;video-container&quot;&gt;&lt;br&gt;&lt;iframe  height=270 width=480 src=&quot;http://player.youku.com/embed/XNDg2OTMzNDEy&quot; frameborder=0 allowfullscreen&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/div&gt;

&lt;h3 id=&quot;Rosmin&quot;&gt;&lt;a href=&quot;#Rosmin&quot; class=&quot;headerlink&quot; title=&quot;Rosmin&quot;&gt;&lt;/a&gt;Rosmin&lt;/h3&gt;&lt;p&gt;项目地址：&lt;a href=&quot;https://code.google.com/p/wtfrobot-rosmin/&quot;&gt;https://code.google.com/p/wtfrobot-rosmin/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;相关文章：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/8029640/&quot;&gt;Rosmin–OpenCV Color Blob Tracker on Android&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/8034640/&quot;&gt;Android下PocketSphinx的离线语音识别&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173609/&quot;&gt;Rosmin–OpenCV Color Blob Tracker on Android&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173619/&quot;&gt;Rosmin–两台Android手机的Socket双向通信&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173631/&quot;&gt;Rosmin–在Android上绘制小车行进路线图并标记&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://blog.csdn.net/wtfrobot/article/details/9173643/&quot;&gt;Rosmin–折腾USB Host Shield的日子&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Rosmin机器人是我们去年（2012年）制作的一个使用Arduino驱动的小型移动机器人，连接上Android手机，可以完成手机控制的基本运动，追踪乒乓球，以QR码为人工路标移动到指定区域，搜寻目标，视频监控等等。&lt;/p&gt;
&lt;p&gt;硬件结构：&lt;br&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/54389a22c578eb6789380abdc70ea156.png&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Robot" scheme="http://www.sun11.me/tags/Robot/"/>
    
  </entry>
  
  <entry>
    <title>ROS on ARM--RK3066上本地编译ROS Groovy</title>
    <link href="http://www.sun11.me/blog/2013/ros-on-arm--native-compilation-on-rk3066/"/>
    <id>http://www.sun11.me/blog/2013/ros-on-arm--native-compilation-on-rk3066/</id>
    <published>2013-02-03T15:08:16.000Z</published>
    <updated>2016-02-07T12:14:38.478Z</updated>
    
    <content type="html">&lt;h3 id=&quot;1-__u5F00_u6E90_u673A_u5668_u4EBA_u64CD_u4F5C_u7CFB_u7EDFROS_28Robot_Operating_System_29_u7B80_u4ECB&quot;&gt;&lt;a href=&quot;#1-__u5F00_u6E90_u673A_u5668_u4EBA_u64CD_u4F5C_u7CFB_u7EDFROS_28Robot_Operating_System_29_u7B80_u4ECB&quot; class=&quot;headerlink&quot; title=&quot;1. 开源机器人操作系统ROS(Robot Operating System)简介&quot;&gt;&lt;/a&gt;1. 开源机器人操作系统ROS(Robot Operating System)简介&lt;/h3&gt;&lt;p&gt;ROS（Robot Operating System）是一个开源的为机器人软件开发设计的软件框架，在异构计算机集群中提供类似操作系统的功能。它并不是一个计算机的操作系统，而是机器人的操作系统，或者称为元级操作系统（Meta Operating System）。据目前唯一一本比较官方的关于ROS的书《ROS By Example Volume 1》介绍，“The primary goal of ROS (pronounced “Ross”) is to provide a unified and open source&lt;br&gt;programming framework for controlling robots in a variety of real world and simulated&lt;br&gt;environments.”，ROS的原始目的就是为了在一系列真实和模拟的环境中控制机器人提供一个统一的开源编程框架。为了实现这一目标，ROS架构中有&lt;a href=&quot;http://www.ros.org/wiki/ROS/Concepts&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;三个层次&lt;/a&gt;的概念：文件系统级（Filesystem Level），计算图级（Computation Graph Level）和社区级（Community Level）。&lt;br&gt;具体可以查阅&lt;a href=&quot;http://zh.wikipedia.org/wiki/ROS&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;维基百科&lt;/a&gt;和&lt;a href=&quot;http://www.ros.org/wiki/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;官网wiki&lt;/a&gt;，这里就不过多介绍了。&lt;/p&gt;
&lt;h3 id=&quot;2-_ROS_Groovy_Galapagos&quot;&gt;&lt;a href=&quot;#2-_ROS_Groovy_Galapagos&quot; class=&quot;headerlink&quot; title=&quot;2. ROS Groovy Galapagos&quot;&gt;&lt;/a&gt;2. ROS Groovy Galapagos&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.ros.org/news/2012/12/ros-groovy-galapagos-released.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;ROS Groovy Galapagos&lt;/a&gt;是2012年12月31日发布的ROS最新版本，主要支持Ubuntu 11.10、Ubuntu 12.04和Ubuntu 12.10。提到这个版本的原因是它采用了新的构建系统——catkin，准备逐渐取代之前的rosbuild。它解决了rosbuild当中的几个问题，让ROS可以持续发展和扩大规模，相对于rosbuild更符合文件系统层次结构标准（Filesystem Hierarchy Standard，FHS），使在其它操作系统和架构上发布ROS包更加容易。正是这个原因让我在MK802 IIIS上编译ROS的时候轻松很多，如果编译之前的版本（比如fuerte）将会遇到更多问题。&lt;/p&gt;
&lt;p&gt;因为catkin的引入，ROS文件系统级的Stacks概念被移除了，原因是Package和Stack之间依赖性跟踪出现的问题，取代的是元包（metapackage）的概念。&lt;/p&gt;
&lt;h3 id=&quot;3-_Ubuntu_on_ARM&quot;&gt;&lt;a href=&quot;#3-_Ubuntu_on_ARM&quot; class=&quot;headerlink&quot; title=&quot;3. Ubuntu on ARM&quot;&gt;&lt;/a&gt;3. Ubuntu on ARM&lt;/h3&gt;&lt;p&gt;ARM版Ubuntu的软件源是在&lt;code&gt;http://ports.ubuntu.com/&lt;/code&gt;上，和桌面版的略有区别，我遇到的一个问题就是桌面版python-*的包ARM版几乎都没有，解决办法是使用python的包管理工具pip安装，比如桌面版上&lt;code&gt;apt-get install python-PACKAGENAME&lt;/code&gt;，用&lt;code&gt;pip install PACKAGENAME&lt;/code&gt;替代。据说easy_install的维护不够好，所以应该尽量用pip。&lt;/p&gt;
&lt;p&gt;我使用的是RK3066上的Picuntu，关于Picuntu请看前一篇文章。&lt;/p&gt;
&lt;h3 id=&quot;4-__u7F16_u8BD1ROS_for_ARM&quot;&gt;&lt;a href=&quot;#4-__u7F16_u8BD1ROS_for_ARM&quot; class=&quot;headerlink&quot; title=&quot;4. 编译ROS for ARM&quot;&gt;&lt;/a&gt;4. 编译ROS for ARM&lt;/h3&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;从前为ARM编译一般都需要在x86的上位机上交叉编译，有一个叫做&lt;a href=&quot;http://www.ros.org/wiki/eros&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;EROS&lt;/a&gt;的项目,但是似乎文档不全，个人觉得用它成功编译的人应该也不多。近几年ARM性能足够强了，在ARM运行的操作系统上直接编译也不是什么问题。所以完全可以参考官网&lt;a href=&quot;http://ros.org/wiki/groovy/Installation/Source&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;从源码编译&lt;/a&gt;的教程，官网还特别搞了一个&lt;a href=&quot;http://ros.org/wiki/groovy/Installation/Raspbian/Source&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;在树莓派上编译&lt;/a&gt;的教程。&lt;/p&gt;
&lt;p&gt;当然，树莓派的内存只有512MB，而且是ARM 11，使用ROS会受到很大的限制，既然它都可以编译ROS Groovy，那么双核A9的RK3066，1G内存就更不是问题了。&lt;/p&gt;
&lt;p&gt;下面一步步按照官网上从源码编译的wiki来：&lt;/p&gt;
&lt;h4 id=&quot;4-1__u5B89_u88C5_u57FA_u7840_u4F9D_u8D56_u5305&quot;&gt;&lt;a href=&quot;#4-1__u5B89_u88C5_u57FA_u7840_u4F9D_u8D56_u5305&quot; class=&quot;headerlink&quot; title=&quot;4.1 安装基础依赖包&quot;&gt;&lt;/a&gt;4.1 安装基础依赖包&lt;/h4&gt;&lt;p&gt;操作系统相关的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install build-essential git python-pip
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ROS Common（或者叫ROS Base，Base Bones什么的）依赖的：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo apt-get install libtinyxml-dev libgtest-dev  liblog4cxx10-dev
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;注意这里只是在Picuntu RC2 上需要额外安装的库，可能你还会遇到其它库的问题。desktop或者desktop-full依赖的库更多，所以更难解决。&lt;/p&gt;
&lt;p&gt;还有一些重要的工具：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo pip install wstool rospkg rosdep
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;可能会遇到很多&lt;code&gt;python-*&lt;/code&gt;的包缺少的问题，需要用&lt;code&gt;sudo pip install PACKAGENAME&lt;/code&gt;安装&lt;/p&gt;
&lt;p&gt;安装完rosdep以后初始化一下：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;sudo rosdep init
rosdep update
&lt;/code&gt;&lt;/pre&gt;&lt;h4 id=&quot;4-2__u6784_u5EFAcatkin_u5305&quot;&gt;&lt;a href=&quot;#4-2__u6784_u5EFAcatkin_u5305&quot; class=&quot;headerlink&quot; title=&quot;4.2 构建catkin包&quot;&gt;&lt;/a&gt;4.2 构建catkin包&lt;/h4&gt;&lt;p&gt;上面提到过，ROS Galapagos采用了新的构建工具catkin代替rosbuild，但并不是所有的包都转换成了catkin的版本，所以先构建ROS的核心包（使用catkin），然后再构建其余的使用rosbuild的部分。&lt;/p&gt;
&lt;h5 id=&quot;4-2-1__u521B_u5EFAcatkin_u5DE5_u4F5C_u7A7A_u95F4&quot;&gt;&lt;a href=&quot;#4-2-1__u521B_u5EFAcatkin_u5DE5_u4F5C_u7A7A_u95F4&quot; class=&quot;headerlink&quot; title=&quot;4.2.1 创建catkin工作空间&quot;&gt;&lt;/a&gt;4.2.1 创建catkin工作空间&lt;/h5&gt;&lt;pre&gt;&lt;code&gt;mkdir ~/ros_catkin_ws
cd ~/ros_catkin_ws
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;下一步是下载核心包的源码并构建它们，你有三种选择：&lt;/p&gt;
&lt;p&gt;Desktop-Full Install: ROS, rqt, rviz, robot-generic libraries, 2D/3D simulators, navigation and 2D/3D perception&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wstool init -j8 src http://packages.ros.org/web/rosinstall/generate/raw/groovy/desktop-full
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Desktop Install : ROS, rqt, rviz, and robot-generic libraries&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wstool init -j8 src http://packages.ros.org/web/rosinstall/generate/raw/groovy/desktop-full
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;ROS-Comm: (Bare Bones) ROS package, build, and communication libraries. No GUI tools.&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wstool init src -j8 http://packages.ros.org/web/rosinstall/generate/raw/groovy/ros_comm
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;这个操作是下载catkin包的代码到&lt;code&gt;~/ros_catkin_ws/src&lt;/code&gt;目录下，-j8是指并行下载8个包，在RK3066上是无压力的，如果是树莓派可能需要减少。&lt;/p&gt;
&lt;p&gt;注意，在后面解决依赖关系和构建的时候很多包依赖的库可能会缺，你可以根据错误提示自行安装所缺的库。我在MK802 IIIS上只成功编译了ROS-Comm，Desktop编译失败了，而Desktop full在官网wiki中说还有问题：&lt;code&gt;There are build errors in desktop-full (gazebo simulator) at the moment, so the desktop variant is suggested at this time. See: https://code.ros.org/trac/ros-pkg/ticket/5595&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;还可以安装其它的包，如robot：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;wstool init -j8 http://packages.ros.org/web/rosinstall/generate/dry/raw/groovy/robot
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;更多的可以在&lt;a href=&quot;http://ros.org/reps/rep-0131.html#variants&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;REP 131&lt;/a&gt;中查阅。&lt;/p&gt;
&lt;h5 id=&quot;4-2-2__u89E3_u51B3_u4F9D_u8D56_u5173_u7CFB&quot;&gt;&lt;a href=&quot;#4-2-2__u89E3_u51B3_u4F9D_u8D56_u5173_u7CFB&quot; class=&quot;headerlink&quot; title=&quot;4.2.2 解决依赖关系&quot;&gt;&lt;/a&gt;4.2.2 解决依赖关系&lt;/h5&gt;&lt;p&gt;在构建包之前你必须确保你解决了所有的依赖关系&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rosdep install --from-paths src --ignore-src --rosdistro groovy -y
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;&lt;code&gt;--from-paths&lt;/code&gt;选项表示我们想要安装某个文件夹下的所有包，这里是&lt;code&gt;src&lt;/code&gt;文件夹。&lt;code&gt;--ignore-src&lt;/code&gt;选项表示rosdep不应该从包管理器安装任何&lt;code&gt;src&lt;/code&gt;文件夹的包，因为我们现在做的就是构建它。&lt;code&gt;--rosdistro&lt;/code&gt;选项之所以需要是因为我们没有设置好ROS的环境，所以我们必须指明我们构建的是ROS的哪个版本。最后，&lt;code&gt;-y&lt;/code&gt;选项表示出现的提示选择都选择&lt;code&gt;yes&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;另外如果你在安装某些包出现错误的情况下仍想安装其它所有可以安装的包，你可以使用-r选项，也就是&lt;code&gt;rosdep install --from-paths src --ignore-src --rosdistro groovy -yr&lt;/code&gt;。&lt;/p&gt;
&lt;h5 id=&quot;4-2-3__u6784_u5EFAcatkin_u5DE5_u4F5C_u7A7A_u95F4&quot;&gt;&lt;a href=&quot;#4-2-3__u6784_u5EFAcatkin_u5DE5_u4F5C_u7A7A_u95F4&quot; class=&quot;headerlink&quot; title=&quot;4.2.3 构建catkin工作空间&quot;&gt;&lt;/a&gt;4.2.3 构建catkin工作空间&lt;/h5&gt;&lt;p&gt;调用&lt;code&gt;catkin_make_isolated&lt;/code&gt;:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;./src/catkin/bin/catkin_make_isolated --install
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;默认安装在&lt;code&gt;~/ros_catkin_ws/install_isolated&lt;/code&gt;下，如果要安装到其它地方，比如&lt;code&gt;/opt/ros/groovy&lt;/code&gt;，可以使用&lt;code&gt;--install-space /opt/ros/groovy&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;如果编译过程中出现错误提示缺少库，需要自行安装解决。&lt;/p&gt;
&lt;p&gt;如果构建完成了，再执行：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source ~/ros_catkin_ws/install_isolated/setup.bash
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;如果你只需要ROS Common那么就结束了。可以测试一下在终端里输入&lt;code&gt;roscore&lt;/code&gt;，我运行的时候报错了，后来注释掉了一个python文件里的几行就跑起来了，具体是哪个文件也忘了，根据报错的信息修改就可以了。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/f0d3de5d6003319e3bee42370fa2b466.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;h4 id=&quot;4-3__u6784_u5EFArosbuild_u5305&quot;&gt;&lt;a href=&quot;#4-3__u6784_u5EFArosbuild_u5305&quot; class=&quot;headerlink&quot; title=&quot;4.3 构建rosbuild包&quot;&gt;&lt;/a&gt;4.3 构建rosbuild包&lt;/h4&gt;&lt;p&gt;只构建ROS Common（Bare Bones）是不需要这一步的，在上一步我也没有成功编译desktop，&lt;br&gt;如果你成功了可以继续下面的步骤：&lt;/p&gt;
&lt;h5 id=&quot;4-3-1__u521B_u5EFArosbuild_u5DE5_u4F5C_u7A7A_u95F4&quot;&gt;&lt;a href=&quot;#4-3-1__u521B_u5EFArosbuild_u5DE5_u4F5C_u7A7A_u95F4&quot; class=&quot;headerlink&quot; title=&quot;4.3.1 创建rosbuild工作空间&quot;&gt;&lt;/a&gt;4.3.1 创建rosbuild工作空间&lt;/h5&gt;&lt;pre&gt;&lt;code&gt;mkdir ~/ros_ws
cd ~/ros_ws
rosws init . ~/ros_catkin_ws/install_isolated
&lt;/code&gt;&lt;/pre&gt;&lt;h5 id=&quot;4-3-2__u4E0B_u8F7DROS_Stacks&quot;&gt;&lt;a href=&quot;#4-3-2__u4E0B_u8F7DROS_Stacks&quot; class=&quot;headerlink&quot; title=&quot;4.3.2 下载ROS Stacks&quot;&gt;&lt;/a&gt;4.3.2 下载ROS Stacks&lt;/h5&gt;&lt;p&gt;Desktop-Full Install: 2d/3d simulators, navigation, robot models and several tutorial stacks&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rosws merge http://packages.ros.org/web/rosinstall/generate/dry/raw/groovy/desktop-full
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Desktop Install: ROS, rqt, rviz, and robot-generic libraries&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rosws merge http://packages.ros.org/web/rosinstall/generate/dry/raw/groovy/desktop
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Desktop-Full仍然有问题：&lt;code&gt;There are build errors in desktop-full (gazebo simulator) at the moment, so the desktop variant is suggested at this time. See: https://code.ros.org/trac/ros-pkg/ticket/5595&lt;/code&gt;&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;rosws update -j8
&lt;/code&gt;&lt;/pre&gt;&lt;h5 id=&quot;4-3-3__u6784_u5EFAROS_Stacks&quot;&gt;&lt;a href=&quot;#4-3-3__u6784_u5EFAROS_Stacks&quot; class=&quot;headerlink&quot; title=&quot;4.3.3 构建ROS Stacks&quot;&gt;&lt;/a&gt;4.3.3 构建ROS Stacks&lt;/h5&gt;&lt;p&gt;下载完后：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;source ~/ros_ws/setup.bash
rosmake -a
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&quot;5-__u5176_u5B83&quot;&gt;&lt;a href=&quot;#5-__u5176_u5B83&quot; class=&quot;headerlink&quot; title=&quot;5. 其它&quot;&gt;&lt;/a&gt;5. 其它&lt;/h3&gt;&lt;p&gt;如果你不满足于ROS Common，而且跟我一样没有成功编译desktop的话，可以试试单独编译其它组件，比如OpenCV和PCL。&lt;/p&gt;
&lt;p&gt;OpenCV 2.4.3的编译非常顺利，几乎没有遇到什么障碍，有GTK+2.0，highgui库都可以正常使用。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/47326a0e384f8fb9d04dcd1eec575f19.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;PCL在我去掉少数几个编译选项以后也成功了，pcl_viewer正常工作。//另外我还安装了OpenNI和Kinect驱动&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/d778fdf85992a2e308d31eb2192dbe64.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;我编译PCL时的CMakeCache.txt在&lt;a href=&quot;https://gist.github.com/4689753&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://gist.github.com/4689753&lt;/a&gt;&lt;/p&gt;
&lt;h3 id=&quot;u53C2_u8003_u8D44_u6599&quot;&gt;&lt;a href=&quot;#u53C2_u8003_u8D44_u6599&quot; class=&quot;headerlink&quot; title=&quot;参考资料&quot;&gt;&lt;/a&gt;参考资料&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;http://en.wikipedia.org/wiki/ROS_(Robot_Operating_System)&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://en.wikipedia.org/wiki/ROS_(Robot_Operating_System)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ros.org/wiki/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ros.org/wiki/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;R. Patrick Goebel,ROS By Example Volume 1&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.ros.org/news/2012/12/ros-groovy-galapagos-released.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.ros.org/news/2012/12/ros-groovy-galapagos-released.html&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://ros.org/wiki/groovy/Installation/Source&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ros.org/wiki/groovy/Installation/Source&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://answers.ros.org/question/10716/ros-on-arm/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://answers.ros.org/question/10716/ros-on-arm/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://ros.org/wiki/groovy/Installation/Raspbian/Source&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ros.org/wiki/groovy/Installation/Raspbian/Source&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;1-__u5F00_u6E90_u673A_u5668_u4EBA_u64CD_u4F5C_u7CFB_u7EDFROS_28Robot_Operating_System_29_u7B80_u4ECB&quot;&gt;&lt;a href=&quot;#1-__u5F00_u6E90_u673A_u5668_u4EBA_u64CD_u4F5C_u7CFB_u7EDFROS_28Robot_Operating_System_29_u7B80_u4ECB&quot; class=&quot;headerlink&quot; title=&quot;1. 开源机器人操作系统ROS(Robot Operating System)简介&quot;&gt;&lt;/a&gt;1. 开源机器人操作系统ROS(Robot Operating System)简介&lt;/h3&gt;&lt;p&gt;ROS（Robot Operating System）是一个开源的为机器人软件开发设计的软件框架，在异构计算机集群中提供类似操作系统的功能。它并不是一个计算机的操作系统，而是机器人的操作系统，或者称为元级操作系统（Meta Operating System）。据目前唯一一本比较官方的关于ROS的书《ROS By Example Volume 1》介绍，“The primary goal of ROS (pronounced “Ross”) is to provide a unified and open source&lt;br&gt;programming framework for controlling robots in a variety of real world and simulated&lt;br&gt;environments.”，ROS的原始目的就是为了在一系列真实和模拟的环境中控制机器人提供一个统一的开源编程框架。为了实现这一目标，ROS架构中有&lt;a href=&quot;http://www.ros.org/wiki/ROS/Concepts&quot;&gt;三个层次&lt;/a&gt;的概念：文件系统级（Filesystem Level），计算图级（Computation Graph Level）和社区级（Community Level）。&lt;br&gt;具体可以查阅&lt;a href=&quot;http://zh.wikipedia.org/wiki/ROS&quot;&gt;维基百科&lt;/a&gt;和&lt;a href=&quot;http://www.ros.org/wiki/&quot;&gt;官网wiki&lt;/a&gt;，这里就不过多介绍了。&lt;/p&gt;
&lt;h3 id=&quot;2-_ROS_Groovy_Galapagos&quot;&gt;&lt;a href=&quot;#2-_ROS_Groovy_Galapagos&quot; class=&quot;headerlink&quot; title=&quot;2. ROS Groovy Galapagos&quot;&gt;&lt;/a&gt;2. ROS Groovy Galapagos&lt;/h3&gt;&lt;p&gt;&lt;a href=&quot;http://www.ros.org/news/2012/12/ros-groovy-galapagos-released.html&quot;&gt;ROS Groovy Galapagos&lt;/a&gt;是2012年12月31日发布的ROS最新版本，主要支持Ubuntu 11.10、Ubuntu 12.04和Ubuntu 12.10。提到这个版本的原因是它采用了新的构建系统——catkin，准备逐渐取代之前的rosbuild。它解决了rosbuild当中的几个问题，让ROS可以持续发展和扩大规模，相对于rosbuild更符合文件系统层次结构标准（Filesystem Hierarchy Standard，FHS），使在其它操作系统和架构上发布ROS包更加容易。正是这个原因让我在MK802 IIIS上编译ROS的时候轻松很多，如果编译之前的版本（比如fuerte）将会遇到更多问题。&lt;/p&gt;
&lt;p&gt;因为catkin的引入，ROS文件系统级的Stacks概念被移除了，原因是Package和Stack之间依赖性跟踪出现的问题，取代的是元包（metapackage）的概念。&lt;/p&gt;
&lt;h3 id=&quot;3-_Ubuntu_on_ARM&quot;&gt;&lt;a href=&quot;#3-_Ubuntu_on_ARM&quot; class=&quot;headerlink&quot; title=&quot;3. Ubuntu on ARM&quot;&gt;&lt;/a&gt;3. Ubuntu on ARM&lt;/h3&gt;&lt;p&gt;ARM版Ubuntu的软件源是在&lt;code&gt;http://ports.ubuntu.com/&lt;/code&gt;上，和桌面版的略有区别，我遇到的一个问题就是桌面版python-*的包ARM版几乎都没有，解决办法是使用python的包管理工具pip安装，比如桌面版上&lt;code&gt;apt-get install python-PACKAGENAME&lt;/code&gt;，用&lt;code&gt;pip install PACKAGENAME&lt;/code&gt;替代。据说easy_install的维护不够好，所以应该尽量用pip。&lt;/p&gt;
&lt;p&gt;我使用的是RK3066上的Picuntu，关于Picuntu请看前一篇文章。&lt;/p&gt;
&lt;h3 id=&quot;4-__u7F16_u8BD1ROS_for_ARM&quot;&gt;&lt;a href=&quot;#4-__u7F16_u8BD1ROS_for_ARM&quot; class=&quot;headerlink&quot; title=&quot;4. 编译ROS for ARM&quot;&gt;&lt;/a&gt;4. 编译ROS for ARM&lt;/h3&gt;
    
    </summary>
    
    
      <category term="Android" scheme="http://www.sun11.me/tags/Android/"/>
    
      <category term="Embedded Linux" scheme="http://www.sun11.me/tags/Embedded-Linux/"/>
    
      <category term="Linux" scheme="http://www.sun11.me/tags/Linux/"/>
    
      <category term="ROS" scheme="http://www.sun11.me/tags/ROS/"/>
    
      <category term="Robot" scheme="http://www.sun11.me/tags/Robot/"/>
    
      <category term="Ubuntu" scheme="http://www.sun11.me/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>ROS on ARM--Picuntu 安装配置</title>
    <link href="http://www.sun11.me/blog/2013/ros-on-arm--picuntu-configuration/"/>
    <id>http://www.sun11.me/blog/2013/ros-on-arm--picuntu-configuration/</id>
    <published>2013-01-28T15:11:32.000Z</published>
    <updated>2016-02-07T12:12:33.510Z</updated>
    
    <content type="html">&lt;p&gt;上篇提到一个叫做Picuntu的项目，目的是为RK3066芯片的设备移植传统Linux，目前基本的使用已经没有什么问题，UG802/MK808（不含MK808B）已经可以使用内置的无线网卡，而其它型号，比如MK802 IIIS或者UG007，由于使用的是MTK的芯片，没有办法找到驱动（话说国内厂商有几个遵守了GPL协议的）所以只能外接USB网卡。另外是VPU和Mali 400，&lt;a href=&quot;http://www.slatedroid.com/topic/41654-pre-alpha-03-ubuntu-linux-for-mk802-iii-ug802-mk808-ug007-imito-mx1/page__st__380&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;slatedroid&lt;/a&gt;论坛里有人正在折腾。&lt;/p&gt;
&lt;p&gt;MK80X开机后一般有两种模式，正常模式和恢复(recovery)模式。所以我们如果需要Android/Linux双启动，就只需要在recovery里刷入linux的kernel，Android可以正常运行互不影响。当然你也可以直接刷入原来的kernel空间覆盖掉Android，但是这种方式并不推荐。官方的recovery似乎功能不多，只有作为u盘的功能。Bob’s Finless ROM是一个修改的ROM，包含了替换recovery等img文件的工具。如果你的设备是MK808/MK808B或者UG802，就可以试试对应的Finless ROM，暂时没有针对其它型号的版本（公元2013年1月28日）。如果其它型号刷入，由于硬件不是都相同，可能会有一些问题。&lt;/p&gt;
&lt;p&gt;需要的工具有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;显示器&lt;br&gt;有HDMI接口直接插上就可以了，如果是VGA或者DVI接口的可以使用转接线，淘宝上有HDMI转VGA带3.5mm音频输出的转接线&lt;/li&gt;
&lt;li&gt;RKAndroidTool v1.35&lt;br&gt;在&lt;a href=&quot;http://www.armtvtech.com/armtvtechforum/viewtopic.php?f=12&amp;amp;t=775&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Bob’s Finless ROM&lt;/a&gt;的包里&lt;/li&gt;
&lt;li&gt;一个大于4G的TF卡或U盘或移动硬盘&lt;/li&gt;
&lt;li&gt;Linux和Windows&lt;br&gt;Windows用于刷入recovery，Linux用于格式化上面所说的TF卡或U盘，写入rootfs。这个要求似乎有点苛刻，但是你可以寻找Windows下用于Ext4文件系统格式化的工具，或者寻找Linux的刷入recovery的工具，但这可能更加麻烦。&lt;/li&gt;
&lt;li&gt;USB网卡&lt;br&gt;如果你的设备不是UG802/MK808&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://rk3066-linux.googlecode.com/files/ug802recovkernel.img&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Kernel镜像&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://download.g8.net/picuntu/picuntu-linuxroot-0.9-RC2.2.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Root file system(Picuntu-linuxroot-0.9-RC2.2.tgz)&lt;/a&gt;&lt;br&gt;你也可以使用一个&lt;a href=&quot;http://download.g8.net/picuntu/pre-picuntu-0.9-RC2.2.tgz&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;安装脚本&lt;/a&gt;来更方便地完成安装过程，但这里介绍最直接（或者麻烦？）的方式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都准备好了的话，开刷吧！&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;h3 id=&quot;1-__u5237_u5165kernel_u955C_u50CF&quot;&gt;&lt;a href=&quot;#1-__u5237_u5165kernel_u955C_u50CF&quot; class=&quot;headerlink&quot; title=&quot;1. 刷入kernel镜像&quot;&gt;&lt;/a&gt;&lt;strong&gt;1. 刷入kernel镜像&lt;/strong&gt;&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;p&gt;把你的设备通过USB线与运行Windows的PC相连，注意不能用只用于供电的Micro USB口连接。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在Android中安装“终端模拟器”，打开终端模拟器输入&lt;code&gt;su&lt;/code&gt;和&lt;code&gt;reboot bootloader&lt;/code&gt;，设备会变成黑屏，Windows会检测到RK30的硬件。然后安装驱动，当然如果之前安装过就不需要。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;打开RKAndroidTool,这时应该显示&lt;code&gt;Found RKAndroid Mass Storage Usb&lt;/code&gt;，而不是&lt;code&gt;No found RKAndroid rock usb&lt;/code&gt;，否则就是你的驱动没有安装好或者设备没有进入bootloader。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;&lt;code&gt;只&lt;/code&gt;选择在recovery空间刷入recovery镜像，几秒之后刷好，立刻自动重启。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;如果你重启以后进入recovery发现一只躺着的带着红色三角形Android，那么可能是你的recovery没有刷对。 //可能的原因是&lt;code&gt;recovery-from-boot.p&lt;/code&gt;这个万恶的文件存在于你的Android系统根目录下，自动恢复原recovery，把它删掉或者重命名&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;刷好以后你将看到Linux的控制台滚屏，然后就可以进行下一步了&lt;/p&gt;
&lt;h3 id=&quot;2-__u521B_u5EFArootfs&quot;&gt;&lt;a href=&quot;#2-__u521B_u5EFArootfs&quot; class=&quot;headerlink&quot; title=&quot;2. 创建rootfs&quot;&gt;&lt;/a&gt;&lt;strong&gt;2. 创建rootfs&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;可以使用4GB以上容量的TF卡、U盘甚至移动硬盘来完成这步。&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;在Linux上打开GParted，在存储设备上创建一个至少4GB的Ext4分区，卷标为&lt;code&gt;linuxroot&lt;/code&gt;  //对，kernel就是根据这个卷标来找文件系统的&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;切换到root用户，解压tar压缩包，使用&lt;code&gt;copy -a&lt;/code&gt;拷贝解压的所有文件和文件夹到linuxroot分区。 //注意最好不要直接解压到linuxroot分区，以我的失败经验做反例，好几次解压以后用不了就是一些文件没有完整复制过去&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;如果进不了登录界面，可能就是一些文件没有完整复制过去，或者你没有切换到root用户，又或者是其它什么原因？比如我。&lt;/p&gt;
&lt;h3 id=&quot;3-__u914D_u7F6E&quot;&gt;&lt;a href=&quot;#3-__u914D_u7F6E&quot; class=&quot;headerlink&quot; title=&quot;3. 配置&quot;&gt;&lt;/a&gt;&lt;strong&gt;3. 配置&lt;/strong&gt;&lt;/h3&gt;&lt;p&gt;首先我是没有成功用Picuntu直接进到图形登录界面的，不知道是哪里出的问题，但是用Ctrl+Alt+F2打开的控制台是可用的，用户名&lt;code&gt;ubuntu&lt;/code&gt;，密码&lt;code&gt;ubuntu&lt;/code&gt;，root用户密码是&lt;code&gt;12qwaszx&lt;/code&gt;，登录以后输入startxfce4可以正常进入图形界面，其它一切功能正常。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;如果&lt;/em&gt; 你的显示器分辨率不够不支持1080p，那么最好用720p，在&lt;code&gt;/etc/rc.local&lt;/code&gt;里取消&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;preprocessor&quot;&gt;# fbset &lt;span class=&quot;number&quot;&gt;1280&lt;/span&gt;x720-&lt;span class=&quot;number&quot;&gt;60&lt;/span&gt;-&lt;span class=&quot;number&quot;&gt;32&lt;/span&gt; -a	 &lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;preprocessor&quot;&gt;# fbset -rgba &lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;16&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;/&lt;span class=&quot;number&quot;&gt;24&lt;/span&gt; -a&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;这两行前面的’#’注释即可。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;如果&lt;/em&gt; 你使用的是USB无线网卡，那么你的设备名应该是wlan1,首先&lt;code&gt;sudo ifconfig wlan1 up&lt;/code&gt;,然后&lt;code&gt;ifconfig&lt;/code&gt;应该能看到你的无线网卡，默认的&lt;code&gt;/etc/network/interfaces&lt;/code&gt;是这样的：&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt; &lt;span class=&quot;preprocessor&quot;&gt;# interfaces(&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;) file used by ifup(&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;) and ifdown(&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; lo&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;iface lo inet loopback&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; usbnet0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;iface usbnet0 inet dhcp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; wlan0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;iface wlan0 inet dhcp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      wpa-ssid Alok_Yamuna&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      wpa-psk abcdefgh&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;你需要改成&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt; &lt;span class=&quot;preprocessor&quot;&gt;# interfaces(&lt;span class=&quot;number&quot;&gt;5&lt;/span&gt;) file used by ifup(&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;) and ifdown(&lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; lo&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;iface lo inet loopback&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; usbnet0&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;iface usbnet0 inet dhcp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;auto&lt;/span&gt; wlan1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;iface wlan1 inet dhcp&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      wpa-ssid your-ssid&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;      wpa-psk your-passwd&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;连上网络之后一切都好办了，各种apt-get。。。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;如果&lt;/em&gt; 你的机器刷坏了，我。。。不负责。。。&lt;/p&gt;
&lt;h3 id=&quot;u53C2_u8003_u8D44_u6599&quot;&gt;&lt;a href=&quot;#u53C2_u8003_u8D44_u6599&quot; class=&quot;headerlink&quot; title=&quot;参考资料&quot;&gt;&lt;/a&gt;参考资料&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;a href=&quot;https://code.google.com/p/rk3066-linux/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://code.google.com/p/rk3066-linux/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.slatedroid.com/topic/41654-pre-alpha-03-ubuntu-linux-for-mk802-iii-ug802-mk808-ug007-imito-mx1/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.slatedroid.com/topic/41654-pre-alpha-03-ubuntu-linux-for-mk802-iii-ug802-mk808-ug007-imito-mx1/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://www.slatedroid.com/topic/46881-picuntu-09-rc-22-bug-fix-version-arrives/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.slatedroid.com/topic/46881-picuntu-09-rc-22-bug-fix-version-arrives/&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://ubuntu.g8.net/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://ubuntu.g8.net/&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;上篇提到一个叫做Picuntu的项目，目的是为RK3066芯片的设备移植传统Linux，目前基本的使用已经没有什么问题，UG802/MK808（不含MK808B）已经可以使用内置的无线网卡，而其它型号，比如MK802 IIIS或者UG007，由于使用的是MTK的芯片，没有办法找到驱动（话说国内厂商有几个遵守了GPL协议的）所以只能外接USB网卡。另外是VPU和Mali 400，&lt;a href=&quot;http://www.slatedroid.com/topic/41654-pre-alpha-03-ubuntu-linux-for-mk802-iii-ug802-mk808-ug007-imito-mx1/page__st__380&quot;&gt;slatedroid&lt;/a&gt;论坛里有人正在折腾。&lt;/p&gt;
&lt;p&gt;MK80X开机后一般有两种模式，正常模式和恢复(recovery)模式。所以我们如果需要Android/Linux双启动，就只需要在recovery里刷入linux的kernel，Android可以正常运行互不影响。当然你也可以直接刷入原来的kernel空间覆盖掉Android，但是这种方式并不推荐。官方的recovery似乎功能不多，只有作为u盘的功能。Bob’s Finless ROM是一个修改的ROM，包含了替换recovery等img文件的工具。如果你的设备是MK808/MK808B或者UG802，就可以试试对应的Finless ROM，暂时没有针对其它型号的版本（公元2013年1月28日）。如果其它型号刷入，由于硬件不是都相同，可能会有一些问题。&lt;/p&gt;
&lt;p&gt;需要的工具有：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;显示器&lt;br&gt;有HDMI接口直接插上就可以了，如果是VGA或者DVI接口的可以使用转接线，淘宝上有HDMI转VGA带3.5mm音频输出的转接线&lt;/li&gt;
&lt;li&gt;RKAndroidTool v1.35&lt;br&gt;在&lt;a href=&quot;http://www.armtvtech.com/armtvtechforum/viewtopic.php?f=12&amp;amp;t=775&quot;&gt;Bob’s Finless ROM&lt;/a&gt;的包里&lt;/li&gt;
&lt;li&gt;一个大于4G的TF卡或U盘或移动硬盘&lt;/li&gt;
&lt;li&gt;Linux和Windows&lt;br&gt;Windows用于刷入recovery，Linux用于格式化上面所说的TF卡或U盘，写入rootfs。这个要求似乎有点苛刻，但是你可以寻找Windows下用于Ext4文件系统格式化的工具，或者寻找Linux的刷入recovery的工具，但这可能更加麻烦。&lt;/li&gt;
&lt;li&gt;USB网卡&lt;br&gt;如果你的设备不是UG802/MK808&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://rk3066-linux.googlecode.com/files/ug802recovkernel.img&quot;&gt;Kernel镜像&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;http://download.g8.net/picuntu/picuntu-linuxroot-0.9-RC2.2.tgz&quot;&gt;Root file system(Picuntu-linuxroot-0.9-RC2.2.tgz)&lt;/a&gt;&lt;br&gt;你也可以使用一个&lt;a href=&quot;http://download.g8.net/picuntu/pre-picuntu-0.9-RC2.2.tgz&quot;&gt;安装脚本&lt;/a&gt;来更方便地完成安装过程，但这里介绍最直接（或者麻烦？）的方式&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;都准备好了的话，开刷吧！&lt;/p&gt;
    
    </summary>
    
    
      <category term="Android" scheme="http://www.sun11.me/tags/Android/"/>
    
      <category term="Embedded Linux" scheme="http://www.sun11.me/tags/Embedded-Linux/"/>
    
      <category term="Linux" scheme="http://www.sun11.me/tags/Linux/"/>
    
      <category term="Robot" scheme="http://www.sun11.me/tags/Robot/"/>
    
      <category term="Ubuntu" scheme="http://www.sun11.me/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>ROS on ARM--Linux For RK3066 Mini PC简介</title>
    <link href="http://www.sun11.me/blog/2013/ros-on-arm--linux-for-rk3066/"/>
    <id>http://www.sun11.me/blog/2013/ros-on-arm--linux-for-rk3066/</id>
    <published>2013-01-24T09:27:26.000Z</published>
    <updated>2016-02-07T12:12:02.698Z</updated>
    
    <content type="html">&lt;p&gt;&lt;a href=&quot;http://www.cnbeta.com/articles/188613.htm&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;去年6月左右&lt;/a&gt;国内厂商（瑞科美 Rikomagic）推出了一款叫做MK802的Mini PC。采用Allwinner A10/ 1GHz Cortex-A8做处理器，运行Android 4.0系统，内存512MB或1G。实际上相当于一个没有触摸屏和电池的平板，不过可以用USB OTG连接鼠标键盘，通过HDMI接口输出音视频。&lt;/p&gt;
&lt;p&gt;“少即是多”，正因为它小，靠外部供电而非电池，有很多扩展的可能性，上市以后很火。到现在淘宝一搜MK802，会出现各种各样厂商（比如酷优乐，联力胜）的也叫做MK802或者UG802,MK803,MK808,MK809的之类的产品。可以给它刷上Linux，然后把它当成一个普通PC使用（因为驱动的原因，用自带的Android可能是更好的选择）。或者，不接显示器，做一个Headless Server？接移动硬盘做一个BT下载机？又或者，加上Arduino，连接上各种传感器，作为机器人的主控制器？总之可以做到很多平板做不到的事情。这里有一个简易对照表：&lt;a href=&quot;http://bluefox.com.tw/2012/11/22/%E5%AE%89%E5%8D%93-android-mini-pc-%E7%B0%A1%E6%98%93%E5%B0%8D%E7%85%A7%E8%A1%A8/#more-2654&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://bluefox.com.tw/2012/11/22/%E5%AE%89%E5%8D%93-android-mini-pc-%E7%B0%A1%E6%98%93%E5%B0%8D%E7%85%A7%E8%A1%A8/#more-2654&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MK802的第一代产品是使用全志A10芯片的，在半年后看来这个芯片性能不够强了，运行桌面Ubuntu不是很流畅，但是它的Android ROM和Linux的支持已经比较完善了。后面有一个MK802 II是它的升级版，改动不大，系统基本也可以通用。&lt;/p&gt;
&lt;p&gt;接下来出现了一个UG802,它不是由原来MK802的厂商瑞科美生产的，而是一个叫做酷优乐的公司。在搜索引擎上搜索“酷优乐”这个词都搜不到这个公司的网站。我是问淘宝客服才知道这个公司的网站的（kuyoule.cn），它是第一个使用RK3066芯片（1.66GHz,双核A9）的Mini PC。然后又出现了一个MK808（不知道是哪个产商的）ROM提升到8G，后来的MK808B增加了蓝牙，改进了WiFi天线（原来的好像WiFi信号不太好）。然后瑞科美才推出MK802 III，同样是使用RK3066芯片，不过个人感觉可能质量和ROM支持好一些。然后就是去年12月份推出的MK802 IIIS了，我买的就是这个。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/7f826aef8756ce136c0262bd5a49a17f.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/eccbaf8ff5d4a416e546a1f2e18401b7.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;RK3066的linux源码从一个西班牙的公司释出，然后AndrewDB开始开发，成功跑上了Ubuntu 12.10: &lt;a href=&quot;http://www.slatedroid.com/topic/40717-ubuntu-linux-for-the-ug802/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.slatedroid.com/topic/40717-ubuntu-linux-for-the-ug802/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;AndrewDB开发了一段时间，放出了kernel镜像和rootfs，最后的版本是Pre-Alpha 0.3,在MK802 III/UG802/MK808/UG007/iMito MX1等RK3066芯片的设备上都测试正常。然后他放出了一个Roadmap，就在论坛里神秘消失了==，再也没有出现。。。大神们都是神龙见首不见尾么。。。&lt;/p&gt;
&lt;p&gt;AndrewDB在Google Code上创建了一个叫做&lt;a href=&quot;https://code.google.com/p/rk3066-linux/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;rk3066-linux&lt;/a&gt;的项目,现在主要由AlokSinha2001接手了。他用&lt;a href=&quot;http://ubuntu.g8.net/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;MK808做了一个服务器&lt;/a&gt;，现在已经持续运行一个月了。1月15号正式发布了PicUntu，主要对服务器的用途做了一些改进，做了一个安装脚本还有一个apk的安装导引。目前（2013年1月24日）最新的版本是0.9 RC 2.2，google code不让放那么大的文件下载，于是直接转到了那个用MK808做的网站上提供下载。&lt;/p&gt;
&lt;p&gt;运行起来还算流畅，使用Chromium没有什么问题，用ports.ubuntu.com的软件源安装软件也很方便，只是速度有点慢(似乎没有其它镜像？)。&lt;a href=&quot;http://www.slatedroid.com/topic/41654-pre-alpha-03-ubuntu-linux-for-mk802-iii-ug802-mk808-ug007-imito-mx1/page__st__380&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Mali 400的驱动有人正在尝试中…&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Picuntu的安装在下一篇文章里介绍。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;a href=&quot;http://www.cnbeta.com/articles/188613.htm&quot;&gt;去年6月左右&lt;/a&gt;国内厂商（瑞科美 Rikomagic）推出了一款叫做MK802的Mini PC。采用Allwinner A10/ 1GHz Cortex-A8做处理器，运行Android 4.0系统，内存512MB或1G。实际上相当于一个没有触摸屏和电池的平板，不过可以用USB OTG连接鼠标键盘，通过HDMI接口输出音视频。&lt;/p&gt;
&lt;p&gt;“少即是多”，正因为它小，靠外部供电而非电池，有很多扩展的可能性，上市以后很火。到现在淘宝一搜MK802，会出现各种各样厂商（比如酷优乐，联力胜）的也叫做MK802或者UG802,MK803,MK808,MK809的之类的产品。可以给它刷上Linux，然后把它当成一个普通PC使用（因为驱动的原因，用自带的Android可能是更好的选择）。或者，不接显示器，做一个Headless Server？接移动硬盘做一个BT下载机？又或者，加上Arduino，连接上各种传感器，作为机器人的主控制器？总之可以做到很多平板做不到的事情。这里有一个简易对照表：&lt;a href=&quot;http://bluefox.com.tw/2012/11/22/%E5%AE%89%E5%8D%93-android-mini-pc-%E7%B0%A1%E6%98%93%E5%B0%8D%E7%85%A7%E8%A1%A8/#more-2654&quot;&gt;http://bluefox.com.tw/2012/11/22/%E5%AE%89%E5%8D%93-android-mini-pc-%E7%B0%A1%E6%98%93%E5%B0%8D%E7%85%A7%E8%A1%A8/#more-2654&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;MK802的第一代产品是使用全志A10芯片的，在半年后看来这个芯片性能不够强了，运行桌面Ubuntu不是很流畅，但是它的Android ROM和Linux的支持已经比较完善了。后面有一个MK802 II是它的升级版，改动不大，系统基本也可以通用。&lt;/p&gt;
&lt;p&gt;接下来出现了一个UG802,它不是由原来MK802的厂商瑞科美生产的，而是一个叫做酷优乐的公司。在搜索引擎上搜索“酷优乐”这个词都搜不到这个公司的网站。我是问淘宝客服才知道这个公司的网站的（kuyoule.cn），它是第一个使用RK3066芯片（1.66GHz,双核A9）的Mini PC。然后又出现了一个MK808（不知道是哪个产商的）ROM提升到8G，后来的MK808B增加了蓝牙，改进了WiFi天线（原来的好像WiFi信号不太好）。然后瑞科美才推出MK802 III，同样是使用RK3066芯片，不过个人感觉可能质量和ROM支持好一些。然后就是去年12月份推出的MK802 IIIS了，我买的就是这个。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/7f826aef8756ce136c0262bd5a49a17f.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/eccbaf8ff5d4a416e546a1f2e18401b7.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Android" scheme="http://www.sun11.me/tags/Android/"/>
    
      <category term="Embedded Linux" scheme="http://www.sun11.me/tags/Embedded-Linux/"/>
    
      <category term="Linux" scheme="http://www.sun11.me/tags/Linux/"/>
    
      <category term="Robot" scheme="http://www.sun11.me/tags/Robot/"/>
    
      <category term="Ubuntu" scheme="http://www.sun11.me/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>WTFRobot Rosmin</title>
    <link href="http://www.sun11.me/blog/2012/wtfrobot-rosmin/"/>
    <id>http://www.sun11.me/blog/2012/wtfrobot-rosmin/</id>
    <published>2012-12-15T03:27:35.000Z</published>
    <updated>2016-02-07T12:11:30.962Z</updated>
    
    <content type="html">&lt;div class=&quot;video-container&quot;&gt;&lt;br&gt;&lt;iframe height=&quot;270&quot; width=&quot;480&quot; src=&quot;http://player.youku.com/embed/XNDg2OTMzNDEy&quot; frameborder=&quot;0&quot; allowfullscreen&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/div&gt;

&lt;p&gt;2012年8月，W、T、F三人陆续回到学校。&lt;/p&gt;
&lt;p&gt;因为共同的机器人之梦，这个团队在今年5月份组建。&lt;/p&gt;
&lt;p&gt;首先W同学有了一个想法，觉得可以把ARM11放在小车上，做一些图像处理的工作，然后再连上Arduino控制器控制小车运动，另外用一台Android手机来操控。&lt;/p&gt;
&lt;p&gt;开始考虑用纯Linux加上Qt作为图形界面，用上OpenCV来做。事实上W同学之前因为做过类似的东西对这个已经比较熟悉了。只是由于摄像头驱动以及USB接口只支持1.1的原因，采集摄像头图像的速度非常慢，慢到无法忍受。&lt;/p&gt;
&lt;p&gt; 但是经过多次尝试，发现一款USB摄像头在ARM板厂商的测试程序当中速度很快，效果很理想，问题是厂商并没有开源这个摄像头测试程序的代码，如果要自己做驱动的话就不是一时半会能搞定的了。于是W同学又尝试了把板子刷上Android操作系统，由于有API可以调用，尽管这个程序闭源仍然可以使用。&lt;/p&gt;
&lt;p&gt;于是W同学又从C/C++版本的OpenCV转到Android版本的OpenCV，在Android测试了一下自带的示例程序，发现会花屏。尝试了很多方法都未能解决。后来ARM板的损坏也导致不得不思考新的方案。&lt;/p&gt;
&lt;p&gt;于是就到了8月份。&lt;/p&gt;
&lt;p&gt;F同学由于要做Android客户端程序学习了Android编程。于是想到直接用Android手机代替ARM11开发板，这样会省去很多麻烦。而在这时，Android手机之间的单向socket通信已经基本完成，在解决了一些小问题以后工作很稳定，速度也很快。&lt;/p&gt;
&lt;p&gt;很快，由于F同学曾经有做小车的经验，以及Arduino编程的经验，由Arduino控制的小车耗不费力地就跑了起来。&lt;br&gt;接下来遇到的第一个难题是Arduino与Android的通信。开始买Arduino的时候没有考虑这个问题，但现在需要与Android手机通信，主要有两个办法，蓝牙和USB，我们觉得蓝牙这个东西开关比较麻烦，也可能不够稳定，于是决定直接用USB Accessory，该特性由Android 2.3.4（平板是3.1）以上支持。开始看到很多论坛的帖子说华为中兴的手机不支持，真心捏了一把汗，还好后来证明三个人的手机都是可用的。&lt;/p&gt;
&lt;p&gt;要解决这个问题，F同学查找了很多资料，最终终于完成了Android手机（客户端）传递信息到另一台Android手机（服务器），再由这台服务器传递信息到Arduino控制小车运动。反应很灵敏，效果很不错，非常好的一个玩具遥控车。&lt;/p&gt;
&lt;p&gt;这个时候，bug只是偶尔出现，解决了以后基本就很完美了，工作都非常稳定。&lt;/p&gt;
&lt;p&gt;可是一切才刚刚开始。&lt;/p&gt;
&lt;p&gt;9月份，W研究了众多可用于Android平台上的计算机视觉库，包括OpenCV，SimpleCV，JavaCV以后，最终发现还是OpenCV比较适合，但是由于JNI接口使用觉得过于复杂，没有深入研究下去。于是利用Android上的OpenCV实现了追踪有明显颜色特征的物体（ColorBlob Track）并且绘制出其中心坐标。&lt;/p&gt;
&lt;p&gt;在T同学完成数模一段时间之后，小车的Arduino部分主要转给他负责。买好了舵机，却发现转起来吱吱地响。让舵机云台根据前面所说的图像处理得到的点的位置跟踪目标，经过一个下午调整终于调好了，可舵机已经坏得差不多了，声音很吓人。后来拆开发现里面的齿轮是塑料的！顿时觉得被坑了，180多买来的二自由度舵机云台居然如此劣质！淘宝立刻给差评！后来买了两个20多块的MG995,质量都很好一直用到现在。&lt;/p&gt;
&lt;p&gt;当然这还远远不是结束。接下来我们陆续实现了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;TTS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;小范围英文离线语音识别&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Socket双向通信&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;各种代码的分离和整合&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;F同学开始研究利用Android服务器上的陀螺仪计算角度和客户端的地图绘制。&lt;/p&gt;
&lt;p&gt;借了一个平板过来。。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/ed79edf141de1d98a5f212396be5c3a8.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;然后，设计利用超声波测距检测拐角和使用QR码作为人工路标的导航机制：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/b567f86412ac9a51823976c67d52b27c.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;此图好象是刚刚调通超声波模块，但却不知这是暴风雨前的宁静。&lt;/p&gt;
&lt;p&gt;本以为超声波传感器+Arduino就一切OK了的，可后来发现事情远没有这么简单，因为Arduino Romeo的资源不足，开始认为是定时器不足导致超声波测距和USB Accessory无法使用。可后来尝试了各种方法，这个问题变得越纠结。&lt;/p&gt;
&lt;p&gt;我们于是增加了一个MSP430作为辅助板来控制超声波传感器。调了很多天之后发现还是不可行，最终发现I/O口不足。&lt;/p&gt;
&lt;p&gt;于是我们换用Google ADK。&lt;/p&gt;
&lt;p&gt;可谁知道我们第一次买来的竟然是假货，用了不到24个小时就坏了，后来淘宝退货，立刻买下了另一个原装进口的。这一耽误又是好多天，这个时候星火杯如果按照原计划已经快开始了。&lt;/p&gt;
&lt;p&gt;真假ADK：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/88c8896e89dd13d2092a2cb18ea42480.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在光棍节那天，我们终于完成了超声波和USB Accessory的共同测试！&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/352d794c5728cbe9748f0ce4431ef49f.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;经历了设备大换血之后，下面的一段时间，我们一直在做小车的导航。每天至少几十次的测试。小车跑过了好几百次了吧。还好星火杯也延迟又延迟，否则我们无法有很多时间来改进。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/bb3a855a31c8227a9e786ee8551008cc.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;在前几天，Arduino与Android双向通信问题才完美解决，舵机转动影响陀螺仪的角度问题也基本解决。但在地图绘制方面还有一些不稳定。追踪小球上根据偏离中心距离调整速度，效果好了不少。&lt;/p&gt;
&lt;p&gt;最后来一张Rosmin的笑脸：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/eb075a854a9d6b082b6debca11f4bfcb.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;哈哈，还有牺牲了一个手机壳有时还不得不举着舵机讲电话的T同学。。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/5084405ab64001d9edb1a2a3e91b192b.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;一切还只是刚刚开始&lt;/p&gt;
&lt;p style=&quot;color: #fff;&quot;&gt;The Next is Rossum.&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;div class=&quot;video-container&quot;&gt;&lt;br&gt;&lt;iframe  height=270 width=480 src=&quot;http://player.youku.com/embed/XNDg2OTMzNDEy&quot; frameborder=0 allowfullscreen&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/div&gt;

&lt;p&gt;2012年8月，W、T、F三人陆续回到学校。&lt;/p&gt;
&lt;p&gt;因为共同的机器人之梦，这个团队在今年5月份组建。&lt;/p&gt;
&lt;p&gt;首先W同学有了一个想法，觉得可以把ARM11放在小车上，做一些图像处理的工作，然后再连上Arduino控制器控制小车运动，另外用一台Android手机来操控。&lt;/p&gt;
&lt;p&gt;开始考虑用纯Linux加上Qt作为图形界面，用上OpenCV来做。事实上W同学之前因为做过类似的东西对这个已经比较熟悉了。只是由于摄像头驱动以及USB接口只支持1.1的原因，采集摄像头图像的速度非常慢，慢到无法忍受。&lt;/p&gt;
&lt;p&gt; 但是经过多次尝试，发现一款USB摄像头在ARM板厂商的测试程序当中速度很快，效果很理想，问题是厂商并没有开源这个摄像头测试程序的代码，如果要自己做驱动的话就不是一时半会能搞定的了。于是W同学又尝试了把板子刷上Android操作系统，由于有API可以调用，尽管这个程序闭源仍然可以使用。&lt;/p&gt;
&lt;p&gt;于是W同学又从C/C++版本的OpenCV转到Android版本的OpenCV，在Android测试了一下自带的示例程序，发现会花屏。尝试了很多方法都未能解决。后来ARM板的损坏也导致不得不思考新的方案。&lt;/p&gt;
&lt;p&gt;于是就到了8月份。&lt;/p&gt;
&lt;p&gt;F同学由于要做Android客户端程序学习了Android编程。于是想到直接用Android手机代替ARM11开发板，这样会省去很多麻烦。而在这时，Android手机之间的单向socket通信已经基本完成，在解决了一些小问题以后工作很稳定，速度也很快。&lt;/p&gt;
&lt;p&gt;很快，由于F同学曾经有做小车的经验，以及Arduino编程的经验，由Arduino控制的小车耗不费力地就跑了起来。&lt;br&gt;接下来遇到的第一个难题是Arduino与Android的通信。开始买Arduino的时候没有考虑这个问题，但现在需要与Android手机通信，主要有两个办法，蓝牙和USB，我们觉得蓝牙这个东西开关比较麻烦，也可能不够稳定，于是决定直接用USB Accessory，该特性由Android 2.3.4（平板是3.1）以上支持。开始看到很多论坛的帖子说华为中兴的手机不支持，真心捏了一把汗，还好后来证明三个人的手机都是可用的。&lt;/p&gt;
&lt;p&gt;要解决这个问题，F同学查找了很多资料，最终终于完成了Android手机（客户端）传递信息到另一台Android手机（服务器），再由这台服务器传递信息到Arduino控制小车运动。反应很灵敏，效果很不错，非常好的一个玩具遥控车。&lt;/p&gt;
&lt;p&gt;这个时候，bug只是偶尔出现，解决了以后基本就很完美了，工作都非常稳定。&lt;/p&gt;
&lt;p&gt;可是一切才刚刚开始。&lt;/p&gt;
&lt;p&gt;9月份，W研究了众多可用于Android平台上的计算机视觉库，包括OpenCV，SimpleCV，JavaCV以后，最终发现还是OpenCV比较适合，但是由于JNI接口使用觉得过于复杂，没有深入研究下去。于是利用Android上的OpenCV实现了追踪有明显颜色特征的物体（ColorBlob Track）并且绘制出其中心坐标。&lt;/p&gt;
&lt;p&gt;在T同学完成数模一段时间之后，小车的Arduino部分主要转给他负责。买好了舵机，却发现转起来吱吱地响。让舵机云台根据前面所说的图像处理得到的点的位置跟踪目标，经过一个下午调整终于调好了，可舵机已经坏得差不多了，声音很吓人。后来拆开发现里面的齿轮是塑料的！顿时觉得被坑了，180多买来的二自由度舵机云台居然如此劣质！淘宝立刻给差评！后来买了两个20多块的MG995,质量都很好一直用到现在。&lt;/p&gt;
&lt;p&gt;当然这还远远不是结束。接下来我们陆续实现了：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;TTS&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;小范围英文离线语音识别&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Socket双向通信&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;各种代码的分离和整合&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;F同学开始研究利用Android服务器上的陀螺仪计算角度和客户端的地图绘制。&lt;/p&gt;
&lt;p&gt;借了一个平板过来。。。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/ed79edf141de1d98a5f212396be5c3a8.jpg&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Android" scheme="http://www.sun11.me/tags/Android/"/>
    
      <category term="Robot" scheme="http://www.sun11.me/tags/Robot/"/>
    
  </entry>
  
  <entry>
    <title>Ubuntu12.04美化配置笔记</title>
    <link href="http://www.sun11.me/blog/2012/ubuntu-1204-customization/"/>
    <id>http://www.sun11.me/blog/2012/ubuntu-1204-customization/</id>
    <published>2012-07-28T03:04:00.000Z</published>
    <updated>2016-02-07T12:09:36.402Z</updated>
    
    <content type="html">&lt;p&gt;好久没有玩美化了，前几天装了一下LinuxDeepin12.06，感觉美化做得很好，但是系统有一些问题，比如挂起或长时间锁屏后gnome-settings-daemon开不了，导致快捷键失效，主题风格变成非常好看的win95 style…搜了好多个帖子（前几年ubuntu也出过类似问题）都没解决。最后无奈换回标准Ubuntu，但是看到LinuxDeepin，搞美化的瘾又上来了。&lt;/p&gt;
&lt;p&gt;LinuxDeepin的主题用的是从Zukitwo主题修改而来的仿Mac主题。//为啥我这么清楚？因为它的css文件里的作者没改，上一个版本的Deepin-GTK主题甚至连主题名称也没改还叫Zukitwo。&lt;/p&gt;
&lt;p&gt;在美化方面我完全是Mac控，就连现在的Windows也是任务栏在上，下面RocketDock，主题用nick-zone.com的仿lion主题。Ubuntu的默认主题完全不符合我的审美，于是从LinuxDeepin的iso文件里提取出了主题的文件来用。发现了个小问题，就是打开黑色风格的窗口（如图片查看器）时窗口的上边缘有一条白线，看着灰常不爽（Zukitwo主题没有），去翻它的css，和Zukitwo的css文件diff一下，发现改动很少，于是从Zukitwo的主题开始调整，把几个按钮复制过去，发现按钮偏上了，然后按照Deepin的css改。Zukitwo的主题标题栏文字不居中，照Deepin的改就居中了。&lt;/p&gt;
&lt;p&gt;后来又发现一个Mac-OS-Lion-Theme-V2,做得灰常给力，于是就放弃了自己改的主题用这个了，可是还有一些按钮颜色不是很满意。配合Zukitwo-Cupertino的Gnome-Shell主题非常好。对Zukitwo-Cupertino我也做了点修改，把panel改成了0.8到0.5的透明，左上角那个gnome大脚向右移了一点。至于图标主题，果断用最有名的Faenza。&lt;/p&gt;
&lt;p&gt;后来又发现一个图标主题叫做Faenza-Cupertino。//为什么都叫Cupertino，我查了一下才知道，那是水果总部。。。&lt;/p&gt;
&lt;p&gt;这个主题是从Faenza的基础上改的，文件夹改成了蓝色更像Mac，其它都没变。//好像必须先装Faenza，因为它包里只有文件夹的图标&lt;/p&gt;
&lt;p&gt;于是现在就是Zukitwo-Cupertino+Faenza-Cupertino+Mac-OS-Lion-Theme-V2,忽然想到，会不会也有叫Cupertino的GTK主题？在gnome-look.org上搜，果然有！叫Adwaita-Cupertino,效果比Mac-OS-Lion-Theme-V2还好！&lt;/p&gt;
&lt;p&gt;不过标题栏的宽度实在太窄，关闭最小化最大化按钮之间的间隔也太小，于是我又改了改。&lt;/p&gt;
&lt;p&gt;嗯，现在完全是Cupertino系列了。。。Zukitwo-Cupertino+Faenza-Cupertino+Adwaita-Cupertino,我把GTK主题，窗口主题和gnome-shell主题放在一起，起名叫Cupertino-sun11-modified。图标包要装在另外位置就不放了。&lt;/p&gt;
&lt;p&gt;另外换上Moutain Lion的银河壁纸，换上苹果丽黑字体（后来还是换成了微软雅黑），Cairo-dock用Mac的主题，用PlymouthManager调了一下启动画面（还是比较喜欢那个Ubuntu Sunrise）。&lt;/p&gt;
&lt;p&gt;Faenza的ppa：&lt;a href=&quot;https://launchpad.net/~tiheum/+archive/equinox/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://launchpad.net/~tiheum/+archive/equinox/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Faenza-Cupertino: &lt;a href=&quot;http://gnome-look.org/content/show.php/Faenza-Cupertino?content=129008/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://gnome-look.org/content/show.php/Faenza-Cupertino?content=129008/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Cupertino-sun11-modified: &lt;a href=&quot;http://dl.dropbox.com/u/18802606/Cupertino-sun11-modified.tar.gz/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://dl.dropbox.com/u/18802606/Cupertino-sun11-modified.tar.gz/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Moutain Lion的Galaxy壁纸： &lt;a href=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/499c3ca4a3fc8c4130ee9e2fa602e76e.jpg/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://11zpic-11zpic.stor.sinaapp.com/original/499c3ca4a3fc8c4130ee9e2fa602e76e.jpg/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;网上流传两个版本的丽黑字体：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://dl.dbank.com/c0037ab60k/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://dl.dbank.com/c0037ab60k/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://www.iplaysoft.com/hiragino-sans.html/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.iplaysoft.com/hiragino-sans.html/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;上图：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/ecf7841f17300803c3f310ab500b3b51.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/0641fc7933141de0fbd12004bf2c44d1.png&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/f88f508953919c81045c2bf50dc8af5e.png&quot;&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;好久没有玩美化了，前几天装了一下LinuxDeepin12.06，感觉美化做得很好，但是系统有一些问题，比如挂起或长时间锁屏后gnome-settings-daemon开不了，导致快捷键失效，主题风格变成非常好看的win95 style…搜了好多个帖子（前几年ubuntu也
    
    </summary>
    
    
      <category term="Customize" scheme="http://www.sun11.me/tags/Customize/"/>
    
      <category term="Ubuntu" scheme="http://www.sun11.me/tags/Ubuntu/"/>
    
  </entry>
  
  <entry>
    <title>Tiny6410的OpenCV2.4.2移植笔记</title>
    <link href="http://www.sun11.me/blog/2012/opencv-242-porting-to-tiny6410/"/>
    <id>http://www.sun11.me/blog/2012/opencv-242-porting-to-tiny6410/</id>
    <published>2012-07-25T09:16:00.000Z</published>
    <updated>2016-02-07T12:11:49.490Z</updated>
    
    <content type="html">&lt;p&gt;关于OpenCV在ARM上的移植最经典的应该就是这篇：&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/noodies/article/details/5798434&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;编译OpenCV for arm-linux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;去年在什么都不懂的情况下移植的时候也主要是靠这篇文章，写得很详细，如果你觉得还不够详细的话，推荐个带图的:&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/yr119111/article/details/7732336&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;opencv2.3.1在arm端的移植&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这篇写得也不错:&lt;br&gt;&lt;a href=&quot;http://www.cnblogs.com/s_agapo/archive/2011/11/24/2262346.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Linux下移植OpenCV+Qt到ARM(Tiny6410)总结&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我的环境是Ubuntu12.04,板子是友善之臂的tiny6410。&lt;/p&gt;
&lt;p&gt;首先当然是装好arm-linux-gcc,配置环境变量，输入arm-linux-gcc -v有输出，这步就完成了。&lt;br&gt;然后是cmake,比较方便的是用带界面的cmake-gui,要注意的地方是&lt;strong&gt;CMAKE_INSTALL_PREFIX&lt;/strong&gt;和&lt;strong&gt;WITH_TIFF&lt;/strong&gt;还有&lt;strong&gt;CMAKE_EXE_LINKER_FLAGS&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;第一个参数需要注意是因为我们编译的库是适用于ARM的，不应该直接放在/usr/local里，否则如果装了x86的OpenCV会有冲突，比如改成/usr/local/opencv-arm。第二个参数一般情况下需要去掉勾，因为似乎默认情况下ubuntu是没有这个支持的，要选上得自己装些什么东西。第三个参数是因为OpenCV需要这两个库的支持？我现在也还不太明白，总之加上-lrt和-lpthread就不会报错了。其它参数保持原状基本都不会报错。&lt;/p&gt;
&lt;p&gt;cmake好后下一步是make,对于双核的机器加上-j4参数速度会快很多，但是也发烫，在系统监视器里看到四个线程的CPU都是接近100%,风扇一直呼呼地响。&lt;/p&gt;
&lt;p&gt;然后是配置编译环境了，好像在2.3以后OpenCV的x86版安装好后都会有pkgconfig的.pc文件。//2.3以前的版本不清楚&lt;/p&gt;
&lt;p&gt;所以比较方便的就是用pkgconfig来配置了，它的.pc文件是在/usr/local/lib/pkgconfig下面。这是适用于PC版本的OpenCV的（因为之前已经安装好了x86的OpenCV）。但是只要把那第一行的prefix路径改成ARM版OpenCV的安装路径（也就是上面CMAKE_INSTALL_PREFIX参数的值）就可以直接用了。&lt;a href=&quot;http://blog.csdn.net/yr119111/article/details/7732336&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;opencv2.3.1在arm端的移植&lt;/a&gt;这篇帖子说再Libs里要加上-lrt -lpthread参数，我的环境下似乎不需要，但是加上也没什么问题。&lt;/p&gt;
&lt;p&gt;这样配置好后，arm-linux-gcc编译的时候加上参数`pkg-config –cflags –libs opencv-arm`就行了,比如arm-linux-gcc `pkg-config –cflags –libs opencv-arm` test.c -o test。//在这个情况下.pc文件名是opencv-arm，注意是两个反引号。&lt;br&gt;我用的主要是Qt，所以在.pro文件里加上：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;unix {
    CONFIG += link_pkgconfig
    PKGCONFIG += /usr/local/lib/pkgconfig/opencv-arm.pc
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是编译成功后可能会显示一些警告，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;../../lib/libopencv_core.so, needed by /usr/local/opencv-arm/lib/libopencv_highgui.so, not found (try using -rpath or -rpath-link)
&lt;/code&gt;&lt;/pre&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;这个警告在我的情况下只要把opencv-arm/lib里的.so文件全部放到/opt/FriendlyARM/toolschain/4.5.1/arm-none-linux-gnueabi/sys-root/lib下面就可以解决，但事实上不管这条警告也不会出什么问题，不会影响到程序的运行。//去年移植的时候就一直没管&lt;/p&gt;
&lt;p&gt;但是耗费我四天的根本就不是这些问题有木有啊！我要开始吐槽了有木有啊！&lt;/p&gt;
&lt;p&gt;首先要吐槽一下u盘，有个以前编译好的程序放在u盘上一直不能运行，报错&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;../../lib/libopencv_core.so, needed by /usr/local/opencv-arm/lib/libopencv_highgui.so, not found (try using -rpath or -rpath-link)
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;和编译时那个警告一样，害得我以为是那个警告必须解决掉。后来折腾了好久发现只要把程序拷到板子的存储介质上就直接能运行了！尼玛啊是文件系统还是权限的神马问题啊！于是我就换成用nfs挂载了。&lt;/p&gt;
&lt;p&gt;现在去年编译的那个程序是能运行了，可是新编译的程序都不能和OpenCV库连上，也是报相同的错，好吧，我试过把.so文件放在/lib下，放在/usr/local/opencv-arm/lib下，两个都放，甚至还试过新建好多个文件夹，放在/opt/FriendlyARM/toolschain/4.5.1/arm-none-linux-gnueabi/sys-root/lib下，结果都一样！只有老的程序能运行，新编译的都不行。后来脑袋终于开窍了，既然老程序可以运行，说明我移植的OpenCV库没有问题。于是我尝试直接用armm-linux-gcc编译了一个简单的程序，发现运行正常？！然后不知什么想法让我把新编译的程序拷贝到/mnt下，也就是nfs挂载的那个目录，神奇的事情发生了，它正常运行了！！！&lt;/p&gt;
&lt;p&gt;那么，这究竟是什么原理呢？我到现在还没搞明白。nfs挂载以后，所有挂载的文件都相当于自己原本文件系统里的文件么？还是有权限什么的问题呢？&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;关于OpenCV在ARM上的移植最经典的应该就是这篇：&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/noodies/article/details/5798434&quot;&gt;编译OpenCV for arm-linux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;去年在什么都不懂的情况下移植的时候也主要是靠这篇文章，写得很详细，如果你觉得还不够详细的话，推荐个带图的:&lt;br&gt;&lt;a href=&quot;http://blog.csdn.net/yr119111/article/details/7732336&quot;&gt;opencv2.3.1在arm端的移植&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这篇写得也不错:&lt;br&gt;&lt;a href=&quot;http://www.cnblogs.com/s_agapo/archive/2011/11/24/2262346.html&quot;&gt;Linux下移植OpenCV+Qt到ARM(Tiny6410)总结&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我的环境是Ubuntu12.04,板子是友善之臂的tiny6410。&lt;/p&gt;
&lt;p&gt;首先当然是装好arm-linux-gcc,配置环境变量，输入arm-linux-gcc -v有输出，这步就完成了。&lt;br&gt;然后是cmake,比较方便的是用带界面的cmake-gui,要注意的地方是&lt;strong&gt;CMAKE_INSTALL_PREFIX&lt;/strong&gt;和&lt;strong&gt;WITH_TIFF&lt;/strong&gt;还有&lt;strong&gt;CMAKE_EXE_LINKER_FLAGS&lt;/strong&gt;。&lt;/p&gt;
&lt;p&gt;第一个参数需要注意是因为我们编译的库是适用于ARM的，不应该直接放在/usr/local里，否则如果装了x86的OpenCV会有冲突，比如改成/usr/local/opencv-arm。第二个参数一般情况下需要去掉勾，因为似乎默认情况下ubuntu是没有这个支持的，要选上得自己装些什么东西。第三个参数是因为OpenCV需要这两个库的支持？我现在也还不太明白，总之加上-lrt和-lpthread就不会报错了。其它参数保持原状基本都不会报错。&lt;/p&gt;
&lt;p&gt;cmake好后下一步是make,对于双核的机器加上-j4参数速度会快很多，但是也发烫，在系统监视器里看到四个线程的CPU都是接近100%,风扇一直呼呼地响。&lt;/p&gt;
&lt;p&gt;然后是配置编译环境了，好像在2.3以后OpenCV的x86版安装好后都会有pkgconfig的.pc文件。//2.3以前的版本不清楚&lt;/p&gt;
&lt;p&gt;所以比较方便的就是用pkgconfig来配置了，它的.pc文件是在/usr/local/lib/pkgconfig下面。这是适用于PC版本的OpenCV的（因为之前已经安装好了x86的OpenCV）。但是只要把那第一行的prefix路径改成ARM版OpenCV的安装路径（也就是上面CMAKE_INSTALL_PREFIX参数的值）就可以直接用了。&lt;a href=&quot;http://blog.csdn.net/yr119111/article/details/7732336&quot;&gt;opencv2.3.1在arm端的移植&lt;/a&gt;这篇帖子说再Libs里要加上-lrt -lpthread参数，我的环境下似乎不需要，但是加上也没什么问题。&lt;/p&gt;
&lt;p&gt;这样配置好后，arm-linux-gcc编译的时候加上参数`pkg-config –cflags –libs opencv-arm`就行了,比如arm-linux-gcc `pkg-config –cflags –libs opencv-arm` test.c -o test。//在这个情况下.pc文件名是opencv-arm，注意是两个反引号。&lt;br&gt;我用的主要是Qt，所以在.pro文件里加上：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;unix {
    CONFIG += link_pkgconfig
    PKGCONFIG += /usr/local/lib/pkgconfig/opencv-arm.pc
}
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;但是编译成功后可能会显示一些警告，比如：&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;../../lib/libopencv_core.so, needed by /usr/local/opencv-arm/lib/libopencv_highgui.so, not found (try using -rpath or -rpath-link)
&lt;/code&gt;&lt;/pre&gt;
    
    </summary>
    
    
      <category term="Embedded Linux" scheme="http://www.sun11.me/tags/Embedded-Linux/"/>
    
      <category term="OpenCV" scheme="http://www.sun11.me/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>[译]OpenCV的基础光学字符识别</title>
    <link href="http://www.sun11.me/blog/2012/opencv-basic-ocr/"/>
    <id>http://www.sun11.me/blog/2012/opencv-basic-ocr/</id>
    <published>2012-07-17T09:21:00.000Z</published>
    <updated>2016-02-07T13:17:22.886Z</updated>
    
    <content type="html">&lt;p&gt;From:&lt;a href=&quot;http://blog.damiles.com/2008/11/basic-ocr-in-opencv/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://blog.damiles.com/2008/11/basic-ocr-in-opencv/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Github_u6E90_u7801&quot;&gt;&lt;a href=&quot;#Github_u6E90_u7801&quot; class=&quot;headerlink&quot; title=&quot;Github源码&quot;&gt;&lt;/a&gt;&lt;em&gt;&lt;a href=&quot;https://github.com/damiles/basicOCR&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Github源码&lt;/a&gt;&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;在这个教程当中我们将完成一个基础的数字光学字符识别。这包括把一个手写的数字分类进它所属的类里。&lt;/p&gt;
&lt;p&gt;为了完成它，们我将要使用我们之前的教程里所有学到的东西，我们将要使用简单的&lt;a href=&quot;http://blog.damiles.com/?p=72&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;basic painter&lt;/a&gt;和 &lt;a href=&quot;http://blog.damiles.com/?p=84&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;the basic pattern recognition and classification with openCV&lt;/a&gt; 两个教程。&lt;/p&gt;
&lt;p&gt;在一个典型的模式识别分类器里，包括三个模块：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/9d6e45397b7eb2ed28bafff2460e962a.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 预处理（信号获取和滤波）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 特征提取（特征向量的计算）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 分类（特征向量的分类）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;预处理（Preprocessing）：在这个模块我们将要处理我们输入的图片，比如大小标准化，彩色图像灰度化等等。&lt;/p&gt;
&lt;p&gt;特征提取(Feature extraction)：在这个模块我们转换我们处理后的图像为一个特征向量以便于分类，它可能是像素矩阵转换成向量或者获取轮廓编码链的数据表示。&lt;/p&gt;
&lt;p&gt;分类模块获取特征向量，并训练我们的系统或者说使用一个分类方法（比如knn）把输入的特征向量分类。&lt;/p&gt;
&lt;p&gt;这个基础光学字符识别的流程图如下：&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;600px&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/f7bb4dc01684abdfc722f2b20a53b1ba.jpg&quot;&gt;&lt;/p&gt;
&lt;p&gt;现在我们有由图片组成的一个训练集和一个测试集来训练和测试我们的分类器（knn）。&lt;/p&gt;
&lt;p&gt;我们有1000张手写数字的图片，每个数字100张。我们使用每个数字的50张图片来训练，另外50张来测试我们的系统。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/200/8d31c89d75a8ef4d90ebdce98d21208f.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;接下来我们要做的第一个工作就是对所有训练集的图片预处理，为了完成它我们创建一个预处理函数。在这个函数中，我们输入一张图片和我们想要它在处理后得到的新的长和宽，这个函数讲返回一个标准大小的带有边框的图片。你可以看到更多清楚的处理流程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/8b1221f56d51a478e9116d118df3b774.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;预处理代码：&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;54&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;55&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;56&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;57&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;58&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;59&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;60&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;61&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;62&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;63&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;64&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;65&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;66&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;67&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;68&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;69&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;70&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;71&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;72&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;73&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;74&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;75&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;76&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;77&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;78&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;79&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;80&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;81&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;82&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;83&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;84&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;85&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;86&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;87&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;88&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;89&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;findX&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(IplImage* imgSrc,&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;* min, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;* max)&lt;/span&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; minFound=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvScalar maxVal=cvRealScalar(imgSrc-&amp;gt;width * &lt;span class=&quot;number&quot;&gt;255&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvScalar val=cvRealScalar(&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//For each col sum, if sum &amp;lt; width*255 then we find the min&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//then continue to end to search the max, if sum&amp;lt; width*255 then is new max&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (i=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;; i&amp;lt; imgSrc-&amp;gt;width; i++)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvGetCol(imgSrc, &amp;amp;data, i);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;val= cvSum(&amp;amp;data);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(val.val[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;] &amp;lt; maxVal.val[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;])&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;*max= i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(!minFound)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;*min= i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;minFound= &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; &lt;span class=&quot;title&quot;&gt;findY&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(IplImage* imgSrc,&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;* min, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;* max)&lt;/span&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; minFound=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvScalar maxVal=cvRealScalar(imgSrc-&amp;gt;width * &lt;span class=&quot;number&quot;&gt;255&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvScalar val=cvRealScalar(&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//For each col sum, if sum &amp;lt; width*255 then we find the min&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//then continue to end to search the max, if sum&amp;lt; width*255 then is new max&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt; (i=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;; i&amp;lt; imgSrc-&amp;gt;height; i++)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvGetRow(imgSrc, &amp;amp;data, i);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;val= cvSum(&amp;amp;data);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(val.val[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;] &amp;lt; maxVal.val[&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;])&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;*max=i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(!minFound)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;*min= i;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;minFound= &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;CvRect &lt;span class=&quot;title&quot;&gt;findBB&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(IplImage* imgSrc)&lt;/span&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvRect aux;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; xmin, xmax, ymin, ymax;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;xmin=xmax=ymin=ymax=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;findX(imgSrc, &amp;amp;xmin, &amp;amp;xmax);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;findY(imgSrc, &amp;amp;ymin, &amp;amp;ymax);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;aux=cvRect(xmin, ymin, xmax-xmin, ymax-ymin);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//printf(&quot;BB: %d,%d - %d,%d\n&quot;, aux.x, aux.y, aux.width, aux.height);&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; aux;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;IplImage &lt;span class=&quot;title&quot;&gt;preprocessing&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(IplImage* imgSrc,&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; new_width, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; new_height)&lt;/span&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage* result;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage* scaledResult;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat dataA;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvRect bb;&lt;span class=&quot;comment&quot;&gt;//bounding box&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvRect bba;&lt;span class=&quot;comment&quot;&gt;//boundinb box maintain aspect ratio&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Find bounding box&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;bb=findBB(imgSrc);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Get bounding box data and no with aspect ratio, the x and y can be corrupted&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvGetSubRect(imgSrc, &amp;amp;data, cvRect(bb.x, bb.y, bb.width, bb.height));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Create image with this data with width and height with aspect ratio 1&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//then we get highest size betwen width and height of our bounding box&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; size=(bb.width&amp;gt;bb.height)?bb.width:bb.height;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;result=cvCreateImage( cvSize( size, size ), &lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvSet(result,CV_RGB(&lt;span class=&quot;number&quot;&gt;255&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;255&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;255&lt;/span&gt;),&lt;span class=&quot;literal&quot;&gt;NULL&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Copy de data in center of image&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; x=(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;)&lt;span class=&quot;built_in&quot;&gt;floor&lt;/span&gt;((&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt;)(size-bb.width)/&lt;span class=&quot;number&quot;&gt;2.0f&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; y=(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;)&lt;span class=&quot;built_in&quot;&gt;floor&lt;/span&gt;((&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt;)(size-bb.height)/&lt;span class=&quot;number&quot;&gt;2.0f&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvGetSubRect(result, &amp;amp;dataA, cvRect(x,y,bb.width, bb.height));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvCopy(&amp;amp;data, &amp;amp;dataA, &lt;span class=&quot;literal&quot;&gt;NULL&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Scale result&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;scaledResult=cvCreateImage( cvSize( new_width, new_height ), &lt;span class=&quot;number&quot;&gt;8&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvResize(result, scaledResult, CV_INTER_NN);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Return processed data&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; *scaledResult;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;我们使用basicOCR类的getData函数来创建训练数据和训练类，这个函数获取所有在OCR文件夹下的图片来创建训练数据，OCR文件夹中的每个类是一个文件夹，其中每个文件都是名为cnn.pbm的pbm文件，c是类（0,1,…,9）中的一个，nn是图片的编号(00,01,…,99)。&lt;/p&gt;
&lt;p&gt;我们得到的每张图片都是预处理过的了，然后他们将转换成特征向量里的数据以便我们使用。&lt;/p&gt;
&lt;p&gt;basicOCR.cpp 获取数据代码：&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; basicOCR::getData()&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage* src_image;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage prs_image;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat row,data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;char&lt;/span&gt; file[&lt;span class=&quot;number&quot;&gt;255&lt;/span&gt;];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i,j;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt;(i =&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;; i&amp;lt;classes; i++)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt;( j = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;; j&amp;lt; train_samples; j++)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Load file&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(j&amp;lt;&lt;span class=&quot;number&quot;&gt;10&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;sprintf&lt;/span&gt;(file,&lt;span class=&quot;string&quot;&gt;&quot;%s%d/%d0%d.pbm&quot;&lt;/span&gt;,file_path, i, i , j);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;sprintf&lt;/span&gt;(file,&lt;span class=&quot;string&quot;&gt;&quot;%s%d/%d%d.pbm&quot;&lt;/span&gt;,file_path, i, i , j);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;src_image = cvLoadImage(file,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(!src_image)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Error: Cant load image %s\n&quot;&lt;/span&gt;, file);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//exit(-1);&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//process file&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;prs_image = preprocessing(src_image, size, size);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Set class label&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvGetRow(trainClasses, &amp;amp;row, i*train_samples + j);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvSet(&amp;amp;row, cvRealScalar(i));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Set data&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvGetRow(trainData, &amp;amp;row, i*train_samples + j);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage* img = cvCreateImage( cvSize( size, size ), IPL_DEPTH_32F, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//convert 8 bits image to 32 float image&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvConvertScale(&amp;amp;prs_image, img, &lt;span class=&quot;number&quot;&gt;0.0039215&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvGetSubRect(img, &amp;amp;data, cvRect(&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, size,size));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat row_header, *row1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//convert data matrix sizexsize to vecor&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;row1 = cvReshape( &amp;amp;data, &amp;amp;row_header, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvCopy(row1, &amp;amp;row, &lt;span class=&quot;literal&quot;&gt;NULL&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;在处理并且得到训练数据和类以后我们用我们的模型训练这些数据，在这个例子中我们用knn方法：&lt;/p&gt;
&lt;p&gt;&lt;code&gt;knn=new CvKNearest( trainData, trainClasses, 0, false, K );&lt;/code&gt;&lt;/p&gt;
&lt;p&gt;现在我们可以测试我们的模型了，并且我们可以使用测试的结果来和其它我们使用的方法比较，又或者我们减小图片大小等等。这里是在我们的basicOCR类里创建的一个函数，测试函数。&lt;/p&gt;
&lt;p&gt;这个函数获取其它500个样本并且用我们选择的方法分类，再检验得到的结果。&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt; basicOCR::test()&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage* src_image;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage prs_image;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat row,data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;char&lt;/span&gt; file[&lt;span class=&quot;number&quot;&gt;255&lt;/span&gt;];&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i,j;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; error=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; testCount=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt;(i =&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;; i&amp;lt;classes; i++)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt;( j = &lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;; j&amp;lt; &lt;span class=&quot;number&quot;&gt;50&lt;/span&gt;+train_samples; j++)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;sprintf&lt;/span&gt;(file,&lt;span class=&quot;string&quot;&gt;&quot;%s%d/%d%d.pbm&quot;&lt;/span&gt;,file_path, i, i , j);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;src_image = cvLoadImage(file,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(!src_image)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Error: Cant load image %s\n&quot;&lt;/span&gt;, file);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//exit(-1);&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//process file&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;prs_image = preprocessing(src_image, size, size);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt; r=classify(&amp;amp;prs_image,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;((&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt;)r!=i)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;error++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;testCount++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt; totalerror=&lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;*(&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt;)error/(&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt;)testCount;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;System Error: %.2f%%\n&quot;&lt;/span&gt;, totalerror);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;test函数使用了分类函数，获取图片，处理图片，得到特征向量并且用knn类的find_nearest函数对其分类。下面&lt;/p&gt;
&lt;p&gt;这个函数我们用来分类输入的用户图片：&lt;/p&gt;
&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt; basicOCR::classify(IplImage* img, &lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; showResult)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage prs_image;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat data;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat* nearest=cvCreateMat(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,K,CV_32FC1);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt; result;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//process file&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;prs_image = preprocessing(img, size, size);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;//Set data&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage* img32 = cvCreateImage( cvSize( size, size ), IPL_DEPTH_32F, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvConvertScale(&amp;amp;prs_image, img32, &lt;span class=&quot;number&quot;&gt;0.0039215&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvGetSubRect(img32, &amp;amp;data, cvRect(&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, size,size));&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat row_header, *row1;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;row1 = cvReshape( &amp;amp;data, &amp;amp;row_header, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;result=knn-&amp;gt;find_nearest(row1,K,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,nearest,&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; accuracy=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;i&amp;lt;K;i++)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;( nearest-&amp;gt;data.fl[i] == result)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;accuracy++;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt; pre=&lt;span class=&quot;number&quot;&gt;100&lt;/span&gt;*((&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt;)accuracy/(&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt;)K);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;(showResult==&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;)&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;|\t%.0f\t| \t%.2f%%&amp;amp;nbsp; \t| \t%d of %d \t| \n&quot;&lt;/span&gt;,result,pre,accuracy,K);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot; ---------------------------------------------------------------\n&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; result;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;所有的工作或者训练和测试都在basicOCR类里，当我们创建一个basicOCR的实例时只需要调用classify函数来分类我们输入的图片。然后我们使用我们之前在其它教程里创建的简单的Painter来给用户交互绘出一张图片并且分类它。&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;注：&lt;/p&gt;
&lt;p&gt;1.knn,即K最邻近结点算法（k-Nearest Neighbor algorithm）,最简单的机器学习算法之一，简单说就是在特征空间里找到周围最近的k个样本，如果这k个样本中的大多数属于某个类，则该样本也属于这个类。&lt;/p&gt;
&lt;p&gt;2.painter,GUI编程中的绘图接口，也就是完成绘制和显示图像的功能。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;https://github.com/damiles/basicOCR&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Github源码&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;From:&lt;a href=&quot;http://blog.damiles.com/2008/11/basic-ocr-in-opencv/&quot;&gt;http://blog.damiles.com/2008/11/basic-ocr-in-opencv/&lt;/a&gt;&lt;/p&gt;
&lt;h2 id=&quot;Github_u6E90_u7801&quot;&gt;&lt;a href=&quot;#Github_u6E90_u7801&quot; class=&quot;headerlink&quot; title=&quot;Github源码&quot;&gt;&lt;/a&gt;&lt;em&gt;&lt;a href=&quot;https://github.com/damiles/basicOCR&quot;&gt;Github源码&lt;/a&gt;&lt;/em&gt;&lt;/h2&gt;&lt;p&gt;在这个教程当中我们将完成一个基础的数字光学字符识别。这包括把一个手写的数字分类进它所属的类里。&lt;/p&gt;
&lt;p&gt;为了完成它，们我将要使用我们之前的教程里所有学到的东西，我们将要使用简单的&lt;a href=&quot;http://blog.damiles.com/?p=72&quot;&gt;basic painter&lt;/a&gt;和 &lt;a href=&quot;http://blog.damiles.com/?p=84&quot;&gt;the basic pattern recognition and classification with openCV&lt;/a&gt; 两个教程。&lt;/p&gt;
&lt;p&gt;在一个典型的模式识别分类器里，包括三个模块：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/9d6e45397b7eb2ed28bafff2460e962a.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 预处理（信号获取和滤波）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 特征提取（特征向量的计算）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt; 分类（特征向量的分类）&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;预处理（Preprocessing）：在这个模块我们将要处理我们输入的图片，比如大小标准化，彩色图像灰度化等等。&lt;/p&gt;
&lt;p&gt;特征提取(Feature extraction)：在这个模块我们转换我们处理后的图像为一个特征向量以便于分类，它可能是像素矩阵转换成向量或者获取轮廓编码链的数据表示。&lt;/p&gt;
&lt;p&gt;分类模块获取特征向量，并训练我们的系统或者说使用一个分类方法（比如knn）把输入的特征向量分类。&lt;/p&gt;
&lt;p&gt;这个基础光学字符识别的流程图如下：&lt;/p&gt;
&lt;p&gt;&lt;img width=&quot;600px&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/f7bb4dc01684abdfc722f2b20a53b1ba.jpg&quot; /&gt;&lt;/p&gt;
&lt;p&gt;现在我们有由图片组成的一个训练集和一个测试集来训练和测试我们的分类器（knn）。&lt;/p&gt;
&lt;p&gt;我们有1000张手写数字的图片，每个数字100张。我们使用每个数字的50张图片来训练，另外50张来测试我们的系统。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/200/8d31c89d75a8ef4d90ebdce98d21208f.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;接下来我们要做的第一个工作就是对所有训练集的图片预处理，为了完成它我们创建一个预处理函数。在这个函数中，我们输入一张图片和我们想要它在处理后得到的新的长和宽，这个函数讲返回一个标准大小的带有边框的图片。你可以看到更多清楚的处理流程：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/8b1221f56d51a478e9116d118df3b774.gif&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="OCR" scheme="http://www.sun11.me/tags/OCR/"/>
    
      <category term="OpenCV" scheme="http://www.sun11.me/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>西电技物论坛</title>
    <link href="http://www.sun11.me/blog/2012/xdjw-forum/"/>
    <id>http://www.sun11.me/blog/2012/xdjw-forum/</id>
    <published>2012-02-20T16:00:00.000Z</published>
    <updated>2016-02-07T11:58:59.214Z</updated>
    
    <content type="html">&lt;p&gt;经过路由器和网关的两层端口映射和两个防火墙端口的开启，CentOS 6.2 + Apache + vsftpd 的小型论坛总算基本建好了。&lt;/p&gt;
&lt;p&gt;&lt;del&gt;地址是&lt;a href=&quot;http://210.27.10.208/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://210.27.10.208/&lt;/a&gt;,仅供西电校内访问。&lt;/del&gt;&lt;/p&gt;
&lt;p&gt;现在校内外均可访问&lt;a href=&quot;http://f120.tk/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://f120.tk/&lt;/a&gt;，ftp服务只有校内可以访问。&lt;/p&gt;
&lt;p&gt;这可折腾了好久时间。我想我把路由器，网关之类的概念算是理解透了。&lt;/p&gt;
&lt;p&gt;碰到各种各样的问题，linux的用户权限，防火墙，端口映射，配置文件…&lt;/p&gt;
&lt;p&gt;还好最后都一一解决了。&lt;/p&gt;
&lt;p&gt;采用wordpress做模板，用了v2press主题，于是它就变身论坛。&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;经过路由器和网关的两层端口映射和两个防火墙端口的开启，CentOS 6.2 + Apache + vsftpd 的小型论坛总算基本建好了。&lt;/p&gt;
&lt;p&gt;&lt;del&gt;地址是&lt;a href=&quot;http://210.27.10.208/&quot; target=&quot;_blank&quot; rel=
    
    </summary>
    
    
      <category term="Web" scheme="http://www.sun11.me/tags/Web/"/>
    
  </entry>
  
  <entry>
    <title>TL-WR703n挂载USB摄像头</title>
    <link href="http://www.sun11.me/blog/2012/tl-wr703n-usb-camera/"/>
    <id>http://www.sun11.me/blog/2012/tl-wr703n-usb-camera/</id>
    <published>2012-01-06T16:00:00.000Z</published>
    <updated>2016-02-07T12:01:55.106Z</updated>
    
    <content type="html">&lt;p&gt;首先刷OpenWrt,我用的是&lt;a title=&quot;http://www.right.com.cn/forum/thread-71042-1-2.html&quot; href=&quot;http://www.right.com.cn/forum/thread-71042-1-2.html&quot; target=&quot;_blank&quot;&gt;这个帖子&lt;/a&gt;里的&lt;a title=&quot;http://ishare.iask.sina.com.cn/f/22200677.html&quot; href=&quot;http://ishare.iask.sina.com.cn/f/22200677.html&quot; target=&quot;_blank&quot;&gt;这个版本&lt;/a&gt;，由于路由器容量较小，一定要先搞定U盘挂载，把安装ipk软件装在u盘上，否则没装几个软件路由器就空间不足了。&lt;/p&gt;
&lt;p&gt;我是按&lt;a title=&quot;http://www.unxmail.com/read.php?187&quot; href=&quot;http://www.unxmail.com/read.php?187&quot; target=&quot;_blank&quot;&gt;这个帖子&lt;/a&gt;来操作的，把u盘分成两个区，一个ext3格式（据说比较稳定？），一个ext4格式。按照帖子成功挂载以后点开luci的System里的Software，发现空间已经是u盘那个指定分区的空间了，啊哈，想装啥就装啥。&lt;/p&gt;
&lt;p&gt;接下来就是摄像头了。由于路由器只有一个usb口，所以得用hub。（废话）&lt;/p&gt;
&lt;p&gt;我看到了&lt;a title=&quot;http://www.openwrt.org.cn/bbs/forum.php?mod=viewthread&amp;amp;tid=6105&amp;amp;extra=&amp;amp;page=1&quot; href=&quot;http://www.openwrt.org.cn/bbs/forum.php?mod=viewthread&amp;amp;tid=6105&amp;amp;extra=&amp;amp;page=1&quot; target=&quot;_blank&quot;&gt;这个帖子&lt;/a&gt;,软件源是不用改的，所以直接：&lt;/p&gt;
&lt;p&gt;opkg update&lt;/p&gt;
&lt;p&gt;opkg install usbutils&lt;/p&gt;
&lt;p&gt;由于我的摄像头是杂牌的，芯片貌似不是301的，所以这跟多数人用的301方案不同。&lt;/p&gt;
&lt;p&gt;首先在win7的设备管理器查到了我的摄像头的设备信息，搜到了型号。发现和帖子里的芯片型号一样，大喜呀。&lt;/p&gt;
&lt;p&gt;然后我装了kmod-video-gspca-zc3xx（可能不用装的）和kmod-video-uvc。&lt;/p&gt;
&lt;p&gt;结果竟然很快成功了。&lt;/p&gt;
&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;
&lt;p&gt;接下来是：&lt;/p&gt;
&lt;p&gt;opkg install mjpg-streamer&lt;/p&gt;
&lt;p&gt;是’-‘不是’_’，和帖子里的不一样，因为跟那个帖子的软件源不同。&lt;/p&gt;
&lt;p&gt;然后仍然按那个帖子把网页文件上传上去，输入命令：&lt;/p&gt;
&lt;p&gt;mjpg_streamer -i “input_uvc.so -y -d /dev/video0” -o “output_http.so -p 8080 -w /www/camwww”&lt;/p&gt;
&lt;p&gt;就可以在&lt;a href=&quot;http://192.168.0.1:8080/?action=stream看到视频了。&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://192.168.0.1:8080/?action=stream看到视频了。&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;我把画质调到了30,显示速度还可以。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/54539106a4e5c87797caf47aa5676976.png&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-101&quot; title=&quot;Screenshot&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/54539106a4e5c87797caf47aa5676976.png&quot; alt=&quot;&quot; width=&quot;584&quot; height=&quot;328&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;关于输入配置参数：&lt;/p&gt;
&lt;p&gt;-y是关键，默认启动是mjpeg格式，这个就报错。改成YUV格式&lt;/p&gt;
&lt;p&gt;-d指定设备&lt;/p&gt;
&lt;p&gt;-f 制定帧数，默认30帧&lt;/p&gt;
&lt;p&gt;-r指定视频大小，如320×240&lt;/p&gt;
&lt;p&gt;-q指定画质，默认80&lt;/p&gt;
&lt;p&gt;关于输出参数：&lt;/p&gt;
&lt;p&gt;-p 指定端口，这里是8080&lt;/p&gt;
&lt;p&gt;-w 指定网页目录，这里我们设置的是/www/camwww目录&lt;/p&gt;
&lt;p&gt;-c设置通过密码访问&lt;/p&gt;
&lt;p&gt;（注：眼下正值考试之际，无力详细写此教程，关于建立两个wifi，一个连接可以上网的wifi热点，一个作为接入点的部分没写，就忽略了吧。）&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;首先刷OpenWrt,我用的是&lt;a title=&quot;http://www.right.com.cn/forum/thread-71042-1-2.html&quot; href=&quot;http://www.right.com.cn/forum/thread-71042-1-2.html&quot; target=&quot;_blank&quot;&gt;这个帖子&lt;/a&gt;里的&lt;a title=&quot;http://ishare.iask.sina.com.cn/f/22200677.html&quot; href=&quot;http://ishare.iask.sina.com.cn/f/22200677.html&quot; target=&quot;_blank&quot;&gt;这个版本&lt;/a&gt;，由于路由器容量较小，一定要先搞定U盘挂载，把安装ipk软件装在u盘上，否则没装几个软件路由器就空间不足了。&lt;/p&gt;
&lt;p&gt;我是按&lt;a title=&quot;http://www.unxmail.com/read.php?187&quot; href=&quot;http://www.unxmail.com/read.php?187&quot; target=&quot;_blank&quot;&gt;这个帖子&lt;/a&gt;来操作的，把u盘分成两个区，一个ext3格式（据说比较稳定？），一个ext4格式。按照帖子成功挂载以后点开luci的System里的Software，发现空间已经是u盘那个指定分区的空间了，啊哈，想装啥就装啥。&lt;/p&gt;
&lt;p&gt;接下来就是摄像头了。由于路由器只有一个usb口，所以得用hub。（废话）&lt;/p&gt;
&lt;p&gt;我看到了&lt;a title=&quot;http://www.openwrt.org.cn/bbs/forum.php?mod=viewthread&amp;amp;tid=6105&amp;amp;extra=&amp;amp;page=1&quot; href=&quot;http://www.openwrt.org.cn/bbs/forum.php?mod=viewthread&amp;amp;tid=6105&amp;amp;extra=&amp;amp;page=1&quot; target=&quot;_blank&quot;&gt;这个帖子&lt;/a&gt;,软件源是不用改的，所以直接：&lt;/p&gt;
&lt;p&gt;opkg update&lt;/p&gt;
&lt;p&gt;opkg install usbutils&lt;/p&gt;
&lt;p&gt;由于我的摄像头是杂牌的，芯片貌似不是301的，所以这跟多数人用的301方案不同。&lt;/p&gt;
&lt;p&gt;首先在win7的设备管理器查到了我的摄像头的设备信息，搜到了型号。发现和帖子里的芯片型号一样，大喜呀。&lt;/p&gt;
&lt;p&gt;然后我装了kmod-video-gspca-zc3xx（可能不用装的）和kmod-video-uvc。&lt;/p&gt;
&lt;p&gt;结果竟然很快成功了。&lt;/p&gt;
    
    </summary>
    
    
      <category term="Linux" scheme="http://www.sun11.me/tags/Linux/"/>
    
      <category term="OpenWrt" scheme="http://www.sun11.me/tags/OpenWrt/"/>
    
  </entry>
  
  <entry>
    <title>[译]人脸检测与人脸识别简介</title>
    <link href="http://www.sun11.me/blog/2011/face-recognition-introduction-translation/"/>
    <id>http://www.sun11.me/blog/2011/face-recognition-introduction-translation/</id>
    <published>2011-09-28T16:00:00.000Z</published>
    <updated>2016-02-07T12:47:33.282Z</updated>
    
    <content type="html">&lt;p&gt;From: &lt;a href=&quot;http://www.shervinemami.co.cc/faceRecognition.html/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.shervinemami.co.cc/faceRecognition.html/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Translated by 11&lt;/p&gt;
&lt;p&gt;“人脸识别”是一个在计算机视觉和生物特征识别领域十分活跃的话题。这个主题已经被给力地研究了25年，并且最终在安全、机器人学、人机交互、数码摄像机、游戏和娱乐领域得到了广泛应用。&lt;/p&gt;
&lt;p&gt;“人脸识别”大致可分为两个阶段：&lt;/p&gt;
&lt;p&gt;1.人脸检测 搜索一幅图像，寻找一切人脸区域（此处以绿色矩形显示），然后进行图像处理，清理脸部图像以便于更好地识别。&lt;/p&gt;
&lt;p&gt;2.人脸识别 把上一阶段检测处理得到的人脸图像与数据&lt;a href=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/c4874641c9d4ba540d14aa8b64f4d35d.jpg&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;img align=&quot;right&quot; title=&quot;facerecOut&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/c4874641c9d4ba540d14aa8b64f4d35d.jpg&quot; alt=&quot;&quot; width=&quot;174&quot; height=&quot;197&quot; style=&quot;margin: 20px;&quot;&gt;&lt;/a&gt; 库中的已知人脸进行比对，判定人脸对应的人是谁(此处以红色文本显示)。&lt;/p&gt;
&lt;p&gt;2002年后，人脸检测已经可以相当可靠地运作。比如OpenCV的Face Detector,对于一个人直视摄像头得到的较清晰图片，大约有90-95%的准确度。通常来说，当人以侧面对准摄像头或与摄像头成一定角度时，较难检测到人脸，有时需要3D Head Pose Estimation。假如图片亮度不是很好，也较难检测到人脸。脸部的部分区域比另一部分区域明亮，带有阴影，模糊，或者戴眼镜，也会影响检测效果。&lt;/p&gt;
&lt;p&gt;然而，人脸识别却比人脸检测不可靠得多，一般只有30-70%的准确度。20世纪90年代以来，人脸识别一直是一个很重要的研究领域，但仍然十分不可靠，并且每一年都有更多的识别技术被创造，如文章底部所列出的（Alternatives to Eigenfaces such as 3D face recognition or recognition from video.）&lt;/p&gt;
&lt;p&gt;我将向你展示如何使用“特征脸”（Eigenfaces)，也称为主元分析法（Principal Component Analysis or PCA)。相对于普通的神经网络方法（Neural Networks）和Fisher Faces方法来说，这是一个简单和流行的对图片进行的二维人脸识别的方法。&lt;/p&gt;
&lt;p&gt;要学习特征脸方法的理论，你需要阅读Face Recognition With Eigenface from Servo Magazine (April 2007)，可能还需要一些数学算法。&lt;/p&gt;
&lt;p&gt;首先我将向你解释，怎样实现特征脸的命令行离线训练（offline training from the command-line），基于Servo Magazine tutorial and source-code (May 2007)。&lt;/p&gt;
&lt;p&gt;之后，我将说明如何将此扩展成为从网络摄像头进行实时的在线训练:-)&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;&lt;strong&gt;使用OpenCV的Face Detector检测人脸&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;p&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;如上所述，人脸识别的第一个阶段是人脸检测。OpenCV库使得使用它的Haar Cascade Face Detector(也称为Viola-Jones方法)检测正面人脸变得相当简单。&lt;/p&gt;&lt;br&gt;OpenCV里的“cvHaarDetectObjects”函数执行人脸检测，但是这个函数直接用没有意义，所以最好用这个包装好的函数：&lt;br&gt;&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Perform face detection on the input image, using the given Haar Cascade.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Returns a rectangle for the detected region in the given image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;CvRect &lt;span class=&quot;title&quot;&gt;detectFaceInImage&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(IplImage *inputImg, CvHaarClassifierCascade* cascade)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Smallest face size.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvSize minFeatureSize = cvSize(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Only search for 1 face.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; flags = CV_HAAR_FIND_BIGGEST_OBJECT | CV_HAAR_DO_ROUGH_SEARCH;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// How detailed should the search be.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt; search_scale_factor = &lt;span class=&quot;number&quot;&gt;1.1f&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	IplImage *detectImg;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	IplImage *greyImg = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvMemStorage* storage;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvRect rc;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt; t;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvSeq* rects;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvSize size;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i, ms, nFaces;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	storage = cvCreateMemStorage(&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	cvClearMemStorage( storage );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// If the image is color, use a greyscale copy of the image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	detectImg = (IplImage*)inputImg;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (inputImg-&amp;amp;gt;nChannels &amp;amp;gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		size = cvSize(inputImg-&amp;amp;gt;width, inputImg-&amp;amp;gt;height);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		greyImg = cvCreateImage(size, IPL_DEPTH_8U, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		cvCvtColor( inputImg, greyImg, CV_BGR2GRAY );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		detectImg = greyImg;	&lt;span class=&quot;comment&quot;&gt;// Use the greyscale image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Detect all the faces in the greyscale image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	t = (&lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt;)cvGetTickCount();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	rects = cvHaarDetectObjects( detectImg, cascade, storage,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			search_scale_factor, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, flags, minFeatureSize);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	t = (&lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt;)cvGetTickCount() - t;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	ms = cvRound( t / ((&lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt;)cvGetTickFrequency() * &lt;span class=&quot;number&quot;&gt;1000.0&lt;/span&gt;) );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	nFaces = rects-&amp;amp;gt;total;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Face Detection took %d ms and found %d objectsn&quot;&lt;/span&gt;, ms, nFaces);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Get the first detected face (the biggest).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (nFaces &amp;amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		rc = *(CvRect*)cvGetSeqElem( rects, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		rc = cvRect(-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;);	&lt;span class=&quot;comment&quot;&gt;// Couldn&#39;t find the face.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (greyImg)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		cvReleaseImage( &amp;amp;amp;greyImg );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	cvReleaseMemStorage( &amp;amp;amp;storage );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;//cvReleaseHaarClassifierCascade( &amp;amp;amp;cascade );&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; rc;	&lt;span class=&quot;comment&quot;&gt;// Return the biggest face found, or (-1,-1,-1,-1).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br&gt;&lt;a id=&quot;more&quot;&gt;&lt;/a&gt;&lt;br&gt;现在如果你想要在一张图片里寻找人脸，只需要简单地调用“detectFaceInImage”函数。你也需要指定OpenCV使用的人脸分类器(Face Classifier)。比如，OpenCV自带了一些用于正面脸的分类器，也有一些用于侧面脸的，还有眼睛检测，鼻检测，嘴检测，全身检测等等。你实际上可以任意把其它的分类检测器用于此函数，甚至创造你自己定制的分类检测器，比如车或人的检测(&lt;a title=&quot;here&quot; href=&quot;http://note.sonots.com/SciSoftware/haartraining.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;阅读此处&lt;/a&gt;)，但既然正脸检测是唯一十分可靠的，这将是我们唯一要讨论的。&lt;p&gt;&lt;/p&gt;
&lt;p&gt;对于正面人脸检测，你应该选取这些OpenCV自带的haar级联分类器(Haar Cascade Classifiers,in the “datahaarcascades” folder)。&lt;/p&gt;
&lt;p&gt;&lt;ul&gt;&lt;br&gt;    &lt;li&gt;“haarcascade_frontalface_default.xml”&lt;/li&gt;&lt;br&gt;    &lt;li&gt;“haarcascade_frontalface_alt.xml”&lt;/li&gt;&lt;br&gt;    &lt;li&gt;“haarcascade_frontalface_alt2.xml”&lt;/li&gt;&lt;br&gt;    &lt;li&gt;“haarcascade_frontalface_alt_tree.xml”&lt;/li&gt;&lt;br&gt;&lt;/ul&gt;&lt;/p&gt;
&lt;p&gt;&lt;div&gt;每个haar级联分类器都将给出略微不同的结果，这依赖于你的环境因素，所以你甚至可以用全部分类器，把结果结合在一起（如果你想要做尽可能多地检测）。有一些更多的用于眼睛，头部，嘴巴，鼻子的分类器在&lt;a href=&quot;http://gias720.dis.ulpgc.es/Gias/modesto.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Modesto’s page&lt;/a&gt;下载。&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;div&gt;你可以在你的程序里这样做来进行人脸检测：&lt;/div&gt;&lt;br&gt;&lt;figure class=&quot;highlight processing&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Haar Cascade file, used for Face Detection.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;built_in&quot;&gt;char&lt;/span&gt; *faceCascadeFilename = &lt;span class=&quot;string&quot;&gt;&quot;haarcascade_frontalface_alt.xml&quot;&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Load the HaarCascade classifier for face detection.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvHaarClassifierCascade* faceCascade;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;faceCascade = (CvHaarClassifierCascade*)cvLoad(faceCascadeFilename, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt;( !faceCascade ) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	printf(&lt;span class=&quot;string&quot;&gt;&quot;Couldnt load Face detector &#39;%s&#39;n&quot;&lt;/span&gt;, faceCascadeFilename);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;built_in&quot;&gt;exit&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Grab the next frame from the camera.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage *inputImg = cvQueryFrame(&lt;span class=&quot;built_in&quot;&gt;camera&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Perform face detection on the input image, using the given Haar classifier&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvRect faceRect = detectFaceInImage(inputImg, faceCascade);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Make sure a valid face was detected.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (faceRect.&lt;span class=&quot;variable&quot;&gt;width&lt;/span&gt; &amp;amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	printf(&lt;span class=&quot;string&quot;&gt;&quot;Detected a face at (%d,%d)!n&quot;&lt;/span&gt;, faceRect.x, faceRect.y);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;.... Use &lt;span class=&quot;string&quot;&gt;&#39;faceRect&#39;&lt;/span&gt; and &lt;span class=&quot;string&quot;&gt;&#39;inputImg&#39;&lt;/span&gt; ....&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Free the Face Detector resources when the program is finished&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvReleaseHaarClassifierCascade( &amp;amp;amp;cascade );&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;对脸部图像进行预处理以便于识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;br&gt;现在你已经检测到一张人脸，你可以使用那张人脸图片进行人脸识别。然而，假如你尝试这样简单地从一张普通图片直接进行人脸识别的话，你将会至少损失10%的准确率！&lt;p&gt;&lt;/p&gt;
&lt;p&gt;在一个人脸识别系统中，应用多种预处理技术对将要识别的图片进行标准化处理是极其重要的。多数人脸识别算法对光照条件十分敏感，所以假如在暗室训练，在明亮的房间就可能不会被识别出来等等。这个问题可归于“lumination dependent”，并且还有其它很多例子，比如脸部也应当在图片的一个十分固定的位置（比如眼睛位置为相同的像素坐标），固定的大小，旋转角度，头发和装饰，表情（笑，怒等），光照方向（向左或向上等），这就是在进行人脸识别前，使用好的图片预处理过滤器十分重要的原因。你还应该做一些其它事情，比如去除脸部周围的多余像素（如用椭圆遮罩，只显示其内部的人脸区域而不是头发或图片背景，因为他们的变化多于脸部区域）。&lt;/p&gt;
&lt;p&gt;为简单起见，我展示给你的人脸识别系统是使用灰度图像的特征脸方法。所以我将向你说明怎样简单地把彩色图像转化为灰度图像，并且之后简单地使用直方图均衡化（&lt;a href=&quot;http://en.wikipedia.org/wiki/Histogram_equalization&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Histogram Equalization&lt;/a&gt;）作为一种自动的标准化脸部图像亮度和对比度的方法。为了得到更好的结果，你可以使用彩色人脸识别(color face recognition,ideally with color histogram fitting in HSV or another color space instead of RGB)，或者使用更多的预处理，比如边缘增强(edge enhancement),轮廓检测(contour detection),手势检测(motion detection),等等。这份代码把图片调整成一个标准的大小，但是可能会改变脸的纵横比(aspect ratio)。你可以阅读我这里的教程&lt;a title=&quot;http://www.shervinemami.co.cc/imageTransforms.html&quot; href=&quot;http://www.shervinemami.co.cc/imageTransforms.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;HERE&lt;/a&gt;，来了解怎样调整图像大小而不改变它的纵横比。&lt;/p&gt;
&lt;p&gt;你可以看到一个预处理阶段的例子：&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/0a71d260e3cc2557c918a5892b9e0a4e.jpg&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;img class=&quot;size-full wp-image-116 alignnone&quot; title=&quot;facerecProcessing&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/0a71d260e3cc2557c918a5892b9e0a4e.jpg&quot; alt=&quot;&quot; width=&quot;343&quot; height=&quot;96&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;这是把一幅RGB格式的图像或灰度图像转变为灰度图像的基本代码。它还把图像调整成了固定的维度，然后应用直方图均衡化来实现固定的亮度和对比度。&lt;br&gt;&lt;figure class=&quot;highlight lasso&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Either convert the image to greyscale, or use the existing greyscale image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage *imageGrey;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (imageSrc-&lt;span class=&quot;subst&quot;&gt;&amp;amp;&lt;/span&gt;&lt;span class=&quot;literal&quot;&gt;gt&lt;/span&gt;;nChannels == &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	imageGrey = cvCreateImage( cvGetSize(imageSrc), IPL_DEPTH_8U, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Convert from RGB (actually it is BGR) to Greyscale.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	cvCvtCol&lt;span class=&quot;subst&quot;&gt;or&lt;/span&gt;( imageSrc, imageGrey, CV_BGR2GRAY );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt; &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Just use the input image, since it is already Greyscale.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	imageGrey = imageSrc;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Resize the image to be a consistent size, even if the aspect ratio changes.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;IplImage *imageProcessed;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;imageProcessed = cvCreateImage(cvSize(width, height), IPL_DEPTH_8U, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Make the image a fixed size.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// CV_INTER_CUBIC or CV_INTER_LINEAR is good for enlarging, and&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// CV_INTER_AREA is good for shrinking / decimation, but bad at enlarging.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvResize(imageGrey, imageProcessed, CV_INTER_LINEAR);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Give the image a standard brightness and contrast.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvEqualizeHist(imageProcessed, imageProcessed);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;attribute&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;built_in&quot;&gt;..  &lt;/span&gt;Use &lt;span class=&quot;string&quot;&gt;&#39;imageProcessed&#39;&lt;/span&gt; f&lt;span class=&quot;subst&quot;&gt;or&lt;/span&gt; Face Recognition &lt;span class=&quot;attribute&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;built_in&quot;&gt;.&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (imageGrey)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	cvReleaseImage(&lt;span class=&quot;subst&quot;&gt;&amp;amp;&lt;/span&gt;amp;imageGrey);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (imageProcessed)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	cvReleaseImage(&lt;span class=&quot;subst&quot;&gt;&amp;amp;&lt;/span&gt;amp;imageProcessed);&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;把“特征脸”用于人脸识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;br&gt;现在你已经有了一张经过预处理后的脸部图片，你可以使用特征脸(PCA)进行人脸识别。OpenCV自带了执行PCA操作的”cvEigenDecomposite()”函数，然而你需要一个图片数据库(训练集)告诉机器怎样识别当中的人。&lt;p&gt;&lt;/p&gt;
&lt;p&gt;所以你应该收集每个人的一组预处理后的脸部图片用于识别。比如，假如你想要从10人的班级当中识别某个人，你可以为每个人存储20张图片，总共就有200张大小相同(如100×100像素)的经预处理的脸部图片。&lt;/p&gt;
&lt;p&gt;特征脸的理论在Servo Magazine的两篇文章(&lt;a title=&quot;http://www.cognotics.com/opencv/servo_2007_series/part_4/index.html&quot; href=&quot;http://www.cognotics.com/opencv/servo_2007_series/part_4/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Face Recognition with Eigenface&lt;/a&gt;)中解释了，但我仍会在这里尝试着向你解释。&lt;/p&gt;
&lt;p&gt;我们使用“主元分析”把你的200张训练图片转换成一个代表这些训练图片主要区别的“特征脸”集。首先它将会通过获取每个像素的平均值，生成这些图片的“平均人脸图片”。然后特征脸将会与“平均人脸”比较。第一个特征脸是最主要的脸部区别，第二个特征脸是第二重要的脸部区别，等等……直到你有了大约50张代表大多数训练集图片的区别的特征脸。&lt;/p&gt;
&lt;p&gt;&lt;img class=&quot;alignleft size-full&quot; title=&quot;facerecAverageFace&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/2d8eed8219f74225270be7e16f40f52c.jpg&quot; alt=&quot;&quot;&gt;&lt;img class=&quot;alignleft size-full&quot; title=&quot;facerecEigenface0&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/1380ef44406c3de47f7c1b572d9fe8d8.jpg&quot; alt=&quot;&quot; width=&quot;130&quot; height=&quot;150&quot;&gt;&lt;img class=&quot;alignnone size-full&quot; title=&quot;facerecEigenface119&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/a31dc0014de76bf6194e7523e53cdb9f.jpg&quot; alt=&quot;&quot; width=&quot;130&quot; height=&quot;150&quot;&gt;&lt;/p&gt;
&lt;p&gt;在上面这些示例图片中你可以看到平均人脸和第一个以及最后一个特征脸。它们是从一个四人的每人30幅图片的训练集中生成的。注意到，平均人脸显示的是一个普通人的平滑脸部结构，排在最前的一些特征脸显示了一些主要的脸部特征，而最后的特征脸（比如Eigenface 119）主要是图像噪声。你可以在下面看到前32张特征脸。&lt;/p&gt;
&lt;p&gt;&lt;a href=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/e0a93b99f0dbaace7d3b2f583bdd8f7e.jpg&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;&lt;img class=&quot;alignnone size-full wp-image-120&quot; title=&quot;facerecEigenfaces&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/e0a93b99f0dbaace7d3b2f583bdd8f7e.jpg&quot; alt=&quot;&quot; width=&quot;532&quot; height=&quot;307&quot;&gt;&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p style=&quot;text-align: left;&quot;&gt;&lt;strong&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;使用主元分析法进行人脸识别&lt;/span&gt;&lt;/strong&gt;&lt;/p&gt;&lt;br&gt;简单地说，特征脸方法(Principal Component Analysis)计算出了训练集中图片的主要区别，并且用这些“区别”的组合来代表每幅训练图片。&lt;p&gt;&lt;/p&gt;
&lt;p&gt;比如，一张训练图片可能是如下的组成：&lt;/p&gt;
&lt;p&gt;(averageFace) + (&lt;span style=&quot;color: #0000ff;&quot;&gt;13.5&lt;/span&gt;% of eigenface0) - (&lt;span style=&quot;color: #0000ff;&quot;&gt;34.3&lt;/span&gt;% of eigenface1) + (&lt;span style=&quot;color: #0000ff;&quot;&gt;4.7&lt;/span&gt;% of eigenface2) + … + (&lt;span style=&quot;color: #0000ff;&quot;&gt;0.0&lt;/span&gt;% of eigenface199).&lt;/p&gt;
&lt;p&gt;一旦计算出来，就可以认为这张训练图片是这200个比率(ratio)：&lt;/p&gt;
&lt;p&gt;{&lt;span style=&quot;color: #0000ff;&quot;&gt;13.5&lt;/span&gt;, &lt;span style=&quot;color: #0000ff;&quot;&gt;-34.3&lt;/span&gt;, &lt;span style=&quot;color: #0000ff;&quot;&gt;4.7&lt;/span&gt;, …, &lt;span style=&quot;color: #0000ff;&quot;&gt;0.0&lt;/span&gt;}.&lt;/p&gt;
&lt;p&gt;用特征脸图片分别乘以这些比率，并加上平均人脸图片 (average face)，从这200个比率还原这张训练图片是完全可以做到的。但是既然很多排在后面的特征脸是图像噪声或者不会对图片有太大作用，这个比率表可以被降低到只剩下最主要的,比如前30个，不会对图像质量有很大影响。所以现在可以用30个特征脸，平均人脸图片，和一个含有30个比率的表，来代表全部的200张训练图片。&lt;/p&gt;
&lt;p&gt;有趣的是，这意味着，我们已经找到了一种方法把200张图片压缩成31张图片再加上一点点数据，而不丢失很多的图像质量。但是这个教程是关于人脸识别的，而不是图像压缩的，所以我们将会忽略它:-)&lt;/p&gt;
&lt;p&gt;在另一幅图片中识别一个人，可以应用相同的PCA计算，使用相同的200个特征脸来寻找200个代表输入图片的比率。并且仍然可以只保留前30个比率而忽略其余的比率，因为它们是次要的。然后通过搜索这些比率的表，寻找在数据库中已知的20个人，来看谁的前30个比率与输入图片的前30个比率最接近。这就是寻找与输入图片最相似的训练图片的基本方法，总共提供了200张训练图片。&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;&lt;strong&gt;离线命令行训练的实现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;为了实现离线训练，也就是通过命令行(command-line)使用文件作为输入输出，我使用了与Servo Magazine里&lt;a href=&quot;http://www.cognotics.com/opencv/servo_2007_series/part_5/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Face Recognition with Eigenface&lt;/a&gt;相同的实现，所以你可以先阅读这篇文章，但是我做了一些小的改动。&lt;p&gt;&lt;/p&gt;
&lt;p&gt;基本上，从训练图片创建一个人脸识别数据库，就是创建一个列出图片文件和每个文件代表的人的文本文件。&lt;/p&gt;
&lt;p&gt;比如，你可以把这些输入一个名为”4_images_of_2_people.txt”的文本文件：&lt;br&gt;&lt;figure class=&quot;highlight stylus&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; Shervin dataShervinShervin1&lt;span class=&quot;class&quot;&gt;.bmp&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; Shervin dataShervinShervin2&lt;span class=&quot;class&quot;&gt;.bmp&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; Shervin dataShervinShervin3&lt;span class=&quot;class&quot;&gt;.bmp&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; Shervin dataShervinShervin4&lt;span class=&quot;class&quot;&gt;.bmp&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; Chandan dataChandanChandan1&lt;span class=&quot;class&quot;&gt;.bmp&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; Chandan dataChandanChandan2&lt;span class=&quot;class&quot;&gt;.bmp&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; Chandan dataChandanChandan3&lt;span class=&quot;class&quot;&gt;.bmp&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;number&quot;&gt;2&lt;/span&gt; Chandan dataChandanChandan4.bmp&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br&gt;它告诉这个程序，第一个人的名字叫“Shervin”，而Shervin的四张预处理后的脸部图像在”dataShervin”文件夹，第二个人的名字叫”Chandan”，在”dataChandan”中有她的四张图片。这个程序可以使用”loadFaceImgArray()”函数把这些图片加载到一个图片数组中。注意，为了简单起见，它不允许空格或特殊字符出现在人名中，&amp;lt;?&amp;gt;所以你可能想要实现这一功能，或者把人名中的空格用下划线代替（比如 Shervin_Emami）。&amp;lt;/?&amp;gt;&lt;/p&gt;
&lt;p&gt;为了从这些加载好的图片中创建一个数据库，你可以使用OpenCV的”cvCalcEigenObjects()”和”cvEigenDecomposite()”函数，比如：&lt;br&gt;&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Tell PCA to quit when it has enough eigenfaces.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvTermCriteria calcLimit = cvTermCriteria( CV_TERMCRIT_ITER, nEigens, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Compute average image, eigenvectors (eigenfaces) and eigenvalues (ratios).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvCalcEigenObjects(nTrainFaces, (&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt;*)faceImgArr, (&lt;span class=&quot;keyword&quot;&gt;void&lt;/span&gt;*)eigenVectArr,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CV_EIGOBJ_NO_CALLBACK, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &amp;amp;amp;calcLimit,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	pAvgTrainImg, eigenValMat-&amp;amp;gt;data.fl);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Normalize the matrix of eigenvalues.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvNormalize(eigenValMat, eigenValMat, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, CV_L1, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Project each training image onto the PCA subspace.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;CvMat projectedTrainFaceMat = cvCreateMat( nTrainFaces, nEigens, CV_32FC1 );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; offset = projectedTrainFaceMat-&amp;amp;gt;step / &lt;span class=&quot;keyword&quot;&gt;sizeof&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;for&lt;/span&gt;(&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i=&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;; i&amp;amp;lt;nTrainFaces; i++) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	cvEigenDecomposite(faceImgArr[i], nEigens, eigenVectArr, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		pAvgTrainImg, projectedTrainFaceMat-&amp;amp;gt;data.fl + i*offset);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br&gt;现在你有了：&lt;/p&gt;
&lt;p&gt;&lt;ul&gt;&lt;br&gt;    &lt;li&gt;平均人脸图片”pAvgTrainImg”，&lt;/li&gt;&lt;br&gt;    &lt;li&gt;包含特征脸图片的数组”eigenVectArr[]”（如：假如你使用了nEigens=200 张训练图片，将得到200 个特征脸），&lt;/li&gt;&lt;br&gt;    &lt;li&gt;特征值矩阵 (即特征脸的比率，eigenface ratios) 每张图片的”projectedTrainFaceMat” 。&lt;/li&gt;&lt;br&gt;&lt;/ul&gt;&lt;/p&gt;
&lt;p&gt;&lt;div&gt;现在这些可以被储存成一个文件，也就是人脸识别的数据库。代码中的”storeTrainingData()”函数将会把这些数据储存到”facedata.xml“文件里，它可以随时被重新载入来识别经训练过的人。代码中也有一个”storeEigenfaceImages()”的函数，生成前面提到的图片，平均人脸图片被保存到”out_averageImage.bmp”，特征脸被保存到”out_eigenfaces.bmp”。&lt;/div&gt;&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;&lt;strong&gt;离线命令行识别的实现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;在离线训练阶段，系统尝试从一个文本文件中的列表读取若干张图像中的人脸，并进行识别。为了实现它，我仍然使用Servo Magazine的&lt;a href=&quot;http://www.cognotics.com/opencv/servo_2007_series/part_5/index.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;Face Recognition with Eigenface&lt;/a&gt;的实现，在此基础上扩展。&lt;p&gt;&lt;/p&gt;
&lt;p&gt;用于离线训练的相同格式的文本文件也可用于离线识别。这个文本文件列出了用于测试的图像文件和对应于这张图像的正确的人名。随后这个程序就对每一幅图片进行识别，并且检验文本文件中的真实值（图片对应的正确人名）来确认其是否识别正确，并统计它的准确率。&lt;/p&gt;
&lt;p&gt;离线识别的实现几乎与离线训练完全相同：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;读取原来的用于训练的文本文件（现在用于识别），把若干个图片文件（预处理后的脸部图片）和名字载入一个图片数组。这些在代码中用“loadFaceImgArray()”函数执行。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;平均人脸，特征脸和特征值（比率）使用函数“loadTrainingData()” 从人脸识别数据库文件（the face recognition database fil）“facedata.xml”载入。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;使用OpenCV的函数“cvEigenDecomposite()”，每张输入的图片都被投影到PCA子空间，来观察哪些特征脸的比率最适合于代表这张图片。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;现在有了特征值（特征脸图片的比率）代表这张输入图片，程序需要查找原始的训练图片，找出拥有最相似比率的图片。这些用数学的方法在“findNearestNeighbor()”函数中执行，采用的是“欧几里得距离（Euclidean Distance）”，但是它只是基本地检查输入图片与每张训练图片的相似性，找到最相似的一张：一张在欧几里得空间上与输入图片距离最近的图片。就像在 Servo Magazine的文章上提到的那样，如果使用马氏距离（ the Mahalanobis space，需要在代码里定义 USE_MAHALANOBIS_DISTANCE），你可以得到更准确的结果。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;在输入图片与最相似图片之间的距离用于确定可信度（confidence）,作为是否识别出某人的指导。1.0的可信度意味着完全相同，0.0或者负的可信度意味着非常不相似。但是需要注意，我在代码中用到的可信度公式只是一个非常基本的可信度测量，不是很可靠，但是我觉得多数人会想要看到一个粗略的可信度值。你可能发现它对你的图片给出错误的值，所以你可以禁用它（比如：把可信度设为恒定的1.0）。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;一旦指导哪张训练图片和输入图片最相似，并假定可信度值不是太低（应该至少是0.6或更高），那么它就指出了那个人是谁，换句话说，它识别出了那个人！&lt;/p&gt;
&lt;p&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;&lt;strong&gt;摄像头实时识别的实现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;要让一个摄像头视频流输入取代文件列表是十分简单的。基本上，你只要从摄像头抓取一帧，而不是读取一个文件，并且一直运行下去直到用户退出，而不是等待文件读取到头就行了。OpenCV为此提供了“cvCreateCameraCapture()”函数（或cvCaptureFromCAM()）。&lt;p&gt;&lt;/p&gt;
&lt;p&gt;从摄像头抓取一帧可以简单地用下面的函数实现：&lt;br&gt;&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Grab the next camera frame. Waits until the next frame is ready, and&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// provides direct access to it, so do NOT modify or free the returned image!&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Will automatically initialize the camera on the first frame.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;IplImage* &lt;span class=&quot;title&quot;&gt;getCameraFrame&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(CvCapture* &amp;amp;amp;camera)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	IplImage *frame;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; w, h;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// If the camera hasn&#39;t been initialized, then open it.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (!camera) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Acessing the camera ...\n&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		camera = cvCreateCameraCapture( &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (!camera) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Couldn&#39;t access the camera.\n&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;built_in&quot;&gt;exit&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;comment&quot;&gt;// Try to set the camera resolution to 320 x 240.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		cvSetCaptureProperty(camera, CV_CAP_PROP_FRAME_WIDTH, &lt;span class=&quot;number&quot;&gt;320&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		cvSetCaptureProperty(camera, CV_CAP_PROP_FRAME_HEIGHT, &lt;span class=&quot;number&quot;&gt;240&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;comment&quot;&gt;// Get the first frame, to make sure the camera is initialized.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		frame = cvQueryFrame( camera );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (frame) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			w = frame-&amp;amp;gt;width;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			h = frame-&amp;amp;gt;height;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Got the camera at %dx%d resolution.\n&quot;&lt;/span&gt;, w, h);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;comment&quot;&gt;// Wait a little, so that the camera can auto-adjust its brightness.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		Sleep(&lt;span class=&quot;number&quot;&gt;1000&lt;/span&gt;);	&lt;span class=&quot;comment&quot;&gt;// (in milliseconds)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Wait until the next camera frame is ready, then grab it.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	frame = cvQueryFrame( camera );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (!frame) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Couldn&#39;t grab a camera frame.\n&quot;&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		&lt;span class=&quot;built_in&quot;&gt;exit&lt;/span&gt;(&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; frame;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br&gt;这个函数可以这样用：&lt;br&gt;&lt;figure class=&quot;highlight gcode&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;C&lt;span class=&quot;title&quot;&gt;vCapture* camera = 0&lt;/span&gt;;	&lt;span class=&quot;comment&quot;&gt;// The camera device.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;keyword&quot;&gt;while&lt;/span&gt; &lt;span class=&quot;comment&quot;&gt;( cvWaitKey(10)&lt;/span&gt; != &lt;span class=&quot;number&quot;&gt;27&lt;/span&gt; ) &amp;#123;	&lt;span class=&quot;comment&quot;&gt;// Quit on &quot;Escape&quot; key.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	IplImage *frame = getCameraFrame&lt;span class=&quot;comment&quot;&gt;(camera)&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	...&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Free the camera.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;cvReleaseCapture&lt;span class=&quot;comment&quot;&gt;( &amp;amp;amp;camera )&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br&gt;请注意，假如你是为windows操作系统开发，你可以使用 Theo Watson 的 &lt;a href=&quot;http://muonics.net/school/spring05/videoInput/&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;videoInput Library v0.1995&lt;/a&gt; 达到两倍于这些代码的速度。它使用了DirectShow硬件加速,然而OpenCV使用VFW已经15年不变了！&lt;br&gt;把我已经解释的这些部分放到一起，人脸识别系统运行步骤如下：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;从摄像头抓取一帧图片。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;转换彩色图片帧为灰度图片帧。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;检测灰度图片帧的人脸。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;处理图片以显示人脸区域（使用 cvSetImageROI() 和 cvCopyImage()）。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;预处理脸部图片。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;识别图片中的人。&lt;br&gt;&lt;/p&gt;&lt;p&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;&lt;strong&gt;摄像头实时训练的实现&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;br&gt;现在你已经有了一个用摄像头实时识别人脸的方法，但是要学习新人脸，你不得不关闭这个程序，把摄像头的图片保存成图片文件，更新图片列表，使用离线命令行训练的方法，然后以实时摄像头识别的模式再次运行这个程序。所以实际上，你完全可以用程序来执行实时的摄像头训练！&lt;p&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;这里就是用摄像头视频流把一个新的人加入人脸识别数据库而不关闭程序的一个最简单的方法：&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;从摄像头收集一些图片（预处理后的脸部图片）,也可以同时执行人脸识别。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;用“cvSaveImage()”函数保存这些脸部图片作为图片文件存入磁盘。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;加入每张脸部图片的文件名到训练图片列表（用于离线命令行训练的文本文件）的底部。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;一旦你准备实时训练，你将从所有图片文件形成的数据库重新训练。这个文本文件列出了新加入的训练图片文件，并且这些图片被电脑存为了图片文件，所以实时训练工作起来跟离线训练一样。&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;但是在重新训练之前，释放任何正在使用的资源和重新初始化也很必要。应该像你重新启动了这个程序一样。比如，在图片被存储成文件并且加入训练列表的文本文件后，你应该再执行相同的离线训练（包括从训练列表文件载入图片，用PCA方法找出新训练集的特征脸和比率）之前释放特征脸数组。 这个实时训练的方法相当低效，因为假如在训练集中有50个人，而你多加了一个人，它将为51个人重新训练，这是非常不好的，因为训练的时间随着用户或图片数量的增加呈指数级增长。但是假如你只是处理百来张图片，它不需要多少秒就可以完成。&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;文件下载请转到&lt;a title=&quot;http://www.shervinemami.co.cc/faceRecognition.html&quot; href=&quot;http://www.shervinemami.co.cc/faceRecognition.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;原文&lt;/a&gt;。&lt;/p&gt;
&lt;p&gt;The article source is &lt;a title=&quot;http://www.shervinemami.co.cc/faceRecognition.html&quot; href=&quot;http://www.shervinemami.co.cc/faceRecognition.html&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;http://www.shervinemami.co.cc/faceRecognition.html&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;From: &lt;a href=&quot;http://www.shervinemami.co.cc/faceRecognition.html/&quot;&gt;http://www.shervinemami.co.cc/faceRecognition.html/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Translated by 11&lt;/p&gt;
&lt;p&gt;“人脸识别”是一个在计算机视觉和生物特征识别领域十分活跃的话题。这个主题已经被给力地研究了25年，并且最终在安全、机器人学、人机交互、数码摄像机、游戏和娱乐领域得到了广泛应用。&lt;/p&gt;
&lt;p&gt;“人脸识别”大致可分为两个阶段：&lt;/p&gt;
&lt;p&gt;1.人脸检测 搜索一幅图像，寻找一切人脸区域（此处以绿色矩形显示），然后进行图像处理，清理脸部图像以便于更好地识别。&lt;/p&gt;
&lt;p&gt;2.人脸识别 把上一阶段检测处理得到的人脸图像与数据&lt;a href=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/c4874641c9d4ba540d14aa8b64f4d35d.jpg&quot;&gt;&lt;img align=&quot;right&quot; title=&quot;facerecOut&quot; src=&quot;http://11zpic-11zpic.stor.sinaapp.com/original/c4874641c9d4ba540d14aa8b64f4d35d.jpg&quot; alt=&quot;&quot; width=&quot;174&quot; height=&quot;197&quot; style=&quot;margin: 20px;&quot; /&gt;&lt;/a&gt; 库中的已知人脸进行比对，判定人脸对应的人是谁(此处以红色文本显示)。&lt;/p&gt;
&lt;p&gt;2002年后，人脸检测已经可以相当可靠地运作。比如OpenCV的Face Detector,对于一个人直视摄像头得到的较清晰图片，大约有90-95%的准确度。通常来说，当人以侧面对准摄像头或与摄像头成一定角度时，较难检测到人脸，有时需要3D Head Pose Estimation。假如图片亮度不是很好，也较难检测到人脸。脸部的部分区域比另一部分区域明亮，带有阴影，模糊，或者戴眼镜，也会影响检测效果。&lt;/p&gt;
&lt;p&gt;然而，人脸识别却比人脸检测不可靠得多，一般只有30-70%的准确度。20世纪90年代以来，人脸识别一直是一个很重要的研究领域，但仍然十分不可靠，并且每一年都有更多的识别技术被创造，如文章底部所列出的（Alternatives to Eigenfaces such as 3D face recognition or recognition from video.）&lt;/p&gt;
&lt;p&gt;我将向你展示如何使用“特征脸”（Eigenfaces)，也称为主元分析法（Principal Component Analysis or PCA)。相对于普通的神经网络方法（Neural Networks）和Fisher Faces方法来说，这是一个简单和流行的对图片进行的二维人脸识别的方法。&lt;/p&gt;
&lt;p&gt;要学习特征脸方法的理论，你需要阅读Face Recognition With Eigenface from Servo Magazine (April 2007)，可能还需要一些数学算法。&lt;/p&gt;
&lt;p&gt;首先我将向你解释，怎样实现特征脸的命令行离线训练（offline training from the command-line），基于Servo Magazine tutorial and source-code (May 2007)。&lt;/p&gt;
&lt;p&gt;之后，我将说明如何将此扩展成为从网络摄像头进行实时的在线训练:-)&lt;/p&gt;
&lt;p&gt;&lt;p&gt;&lt;span style=&quot;color: #ff6600;&quot;&gt;&lt;strong&gt;使用OpenCV的Face Detector检测人脸&lt;/strong&gt;&lt;/span&gt;&lt;/p&gt;&lt;/p&gt;
&lt;p&gt;&lt;p&gt;如上所述，人脸识别的第一个阶段是人脸检测。OpenCV库使得使用它的Haar Cascade Face Detector(也称为Viola-Jones方法)检测正面人脸变得相当简单。&lt;/p&gt;&lt;br&gt;OpenCV里的“cvHaarDetectObjects”函数执行人脸检测，但是这个函数直接用没有意义，所以最好用这个包装好的函数：&lt;br&gt;&lt;figure class=&quot;highlight cpp&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;2&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;3&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;4&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;5&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;6&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;7&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;8&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;9&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;10&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;11&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;12&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;13&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;14&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;15&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;16&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;17&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;18&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;19&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;20&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;21&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;22&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;23&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;24&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;25&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;26&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;27&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;28&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;29&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;30&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;31&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;32&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;33&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;34&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;35&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;36&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;37&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;38&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;39&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;40&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;41&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;42&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;43&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;44&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;45&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;46&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;47&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;48&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;49&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;50&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;51&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;52&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;53&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Perform face detection on the input image, using the given Haar Cascade.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;comment&quot;&gt;// Returns a rectangle for the detected region in the given image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;span class=&quot;function&quot;&gt;CvRect &lt;span class=&quot;title&quot;&gt;detectFaceInImage&lt;/span&gt;&lt;span class=&quot;params&quot;&gt;(IplImage *inputImg, CvHaarClassifierCascade* cascade)&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Smallest face size.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvSize minFeatureSize = cvSize(&lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;, &lt;span class=&quot;number&quot;&gt;20&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Only search for 1 face.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; flags = CV_HAAR_FIND_BIGGEST_OBJECT | CV_HAAR_DO_ROUGH_SEARCH;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// How detailed should the search be.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;float&lt;/span&gt; search_scale_factor = &lt;span class=&quot;number&quot;&gt;1.1f&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	IplImage *detectImg;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	IplImage *greyImg = &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvMemStorage* storage;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvRect rc;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt; t;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvSeq* rects;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	CvSize size;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;int&lt;/span&gt; i, ms, nFaces;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	storage = cvCreateMemStorage(&lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	cvClearMemStorage( storage );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// If the image is color, use a greyscale copy of the image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	detectImg = (IplImage*)inputImg;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (inputImg-&amp;amp;gt;nChannels &amp;amp;gt; &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;) &amp;#123;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		size = cvSize(inputImg-&amp;amp;gt;width, inputImg-&amp;amp;gt;height);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		greyImg = cvCreateImage(size, IPL_DEPTH_8U, &lt;span class=&quot;number&quot;&gt;1&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		cvCvtColor( inputImg, greyImg, CV_BGR2GRAY );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		detectImg = greyImg;	&lt;span class=&quot;comment&quot;&gt;// Use the greyscale image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Detect all the faces in the greyscale image.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	t = (&lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt;)cvGetTickCount();&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	rects = cvHaarDetectObjects( detectImg, cascade, storage,&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;			search_scale_factor, &lt;span class=&quot;number&quot;&gt;3&lt;/span&gt;, flags, minFeatureSize);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	t = (&lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt;)cvGetTickCount() - t;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	ms = cvRound( t / ((&lt;span class=&quot;keyword&quot;&gt;double&lt;/span&gt;)cvGetTickFrequency() * &lt;span class=&quot;number&quot;&gt;1000.0&lt;/span&gt;) );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	nFaces = rects-&amp;amp;gt;total;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;built_in&quot;&gt;printf&lt;/span&gt;(&lt;span class=&quot;string&quot;&gt;&quot;Face Detection took %d ms and found %d objectsn&quot;&lt;/span&gt;, ms, nFaces);&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;// Get the first detected face (the biggest).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (nFaces &amp;amp;gt; &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt;)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		rc = *(CvRect*)cvGetSeqElem( rects, &lt;span class=&quot;number&quot;&gt;0&lt;/span&gt; );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;else&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		rc = cvRect(-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;,-&lt;span class=&quot;number&quot;&gt;1&lt;/span&gt;);	&lt;span class=&quot;comment&quot;&gt;// Couldn&#39;t find the face.&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;if&lt;/span&gt; (greyImg)&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;		cvReleaseImage( &amp;amp;amp;greyImg );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	cvReleaseMemStorage( &amp;amp;amp;storage );&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;comment&quot;&gt;//cvReleaseHaarClassifierCascade( &amp;amp;amp;cascade );&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;	&lt;span class=&quot;keyword&quot;&gt;return&lt;/span&gt; rc;	&lt;span class=&quot;comment&quot;&gt;// Return the biggest face found, or (-1,-1,-1,-1).&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;span class=&quot;line&quot;&gt;&amp;#125;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;&lt;br&gt;
    
    </summary>
    
    
      <category term="OpenCV" scheme="http://www.sun11.me/tags/OpenCV/"/>
    
  </entry>
  
  <entry>
    <title>一个Quick and Dirty的记事本程序</title>
    <link href="http://www.sun11.me/blog/2011/quick-dirty-text-writer/"/>
    <id>http://www.sun11.me/blog/2011/quick-dirty-text-writer/</id>
    <published>2011-08-20T16:00:00.000Z</published>
    <updated>2016-02-07T11:48:20.690Z</updated>
    
    <content type="html">&lt;p&gt;最近在学QT编程，总算是能做出一个图形界面程序了。&lt;/p&gt;
&lt;p&gt;我用的书是《C++ GUI Qt 4 编程（第二版）》(C++ GUI Programming with Qt4,Second Edition)。书上给我的第一个有主窗口的完整应用程序的例子是一个电子表格程序，那叫一个复杂啊…虽然说基本把QT库的基本内容展现出来了，可是我实在消化不了那么多东西，而且涉及到表格，太过具体，这些比较细节的东西以后未必用的上。&lt;/p&gt;
&lt;p&gt;所以我不打算完整的学下来，转而做一个简单的记事本程序。&lt;/p&gt;
&lt;p&gt;这个程序有基本的标题栏，菜单栏，状态栏…&lt;/p&gt;
&lt;p&gt;只是工具栏被我删掉了，感觉跟菜单栏比较类似，也懒得去做图标…&lt;/p&gt;
&lt;p&gt;我找了一下网上的教程，有直接用Qt Designer图形界面操作的，但太傻瓜化，有些功能还实现不了。还有就是书上的例子，纯代码…而我是要做一个有基本界面还可以打开和保存文件，有剪切复制粘贴功能的记事本，用Qt Designer设计UI，然后再写一些代码。&lt;/p&gt;
&lt;p&gt;所以参考了一个QT官网上的一个教程和书里的制作电子表格的示例程序，做了一个Quick and Dirty的记事本程序。&lt;/p&gt;
&lt;p&gt;之所以Dirty，是因为它甚至还不支持中文！（勿喷，勿喷，写入文件是用一个叫做QTextStream的类弄的，我什么都不知道…）&lt;/p&gt;
&lt;p&gt;同是C++初学者的我，压根搞不清状况。那么多乱七八糟的类和对象。问题是Qt Designer设计的ui对象我搞不懂怎么用代码操作，书上它是纯代码的也没讲。&lt;/p&gt;
&lt;p&gt;后来还是QtCreator这个给力的IDE好使啊，打出ui，再按点号，自动将点号转成”-&amp;gt;”，然后用特殊方式显示“ui”，这是说，它找到了这个对象，原来这个对象就叫ui…查了一下前面的定义，大体上看懂了。。。&lt;/p&gt;
&lt;p&gt;把窗体初始化以后，然后就是各种信号和槽的连接…各种QT的类，揣摩各种语法规则(本人比较懒，不想查书…)，Google各种error…在这个过程中，总算是了解了基本的QT编程。&lt;/p&gt;
&lt;p&gt;最开心的事情：setShortcut(QKeySequence::XXX)是在各种操作系统上的万能钥匙啊，什么快捷键，系统给你，不用写，哈哈～&lt;/p&gt;
&lt;p&gt;代码在&lt;a href=&quot;https://github.com/sun11/QTGUI_Writer&quot; target=&quot;_blank&quot; rel=&quot;external&quot;&gt;https://github.com/sun11/QTGUI_Writer&lt;/a&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;最近在学QT编程，总算是能做出一个图形界面程序了。&lt;/p&gt;
&lt;p&gt;我用的书是《C++ GUI Qt 4 编程（第二版）》(C++ GUI Programming with Qt4,Second Edition)。书上给我的第一个有主窗口的完整应用程序的例子是一个电子表格程序
    
    </summary>
    
    
      <category term="Qt" scheme="http://www.sun11.me/tags/Qt/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="http://www.sun11.me/blog/2011/hello-world/"/>
    <id>http://www.sun11.me/blog/2011/hello-world/</id>
    <published>2011-06-25T16:00:00.000Z</published>
    <updated>2016-02-07T12:20:45.458Z</updated>
    
    <content type="html">&lt;p&gt;&lt;strong&gt;Hello World!&lt;/strong&gt;&lt;/p&gt;
</content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;Hello World!&lt;/strong&gt;&lt;/p&gt;

    
    </summary>
    
    
  </entry>
  
</feed>
